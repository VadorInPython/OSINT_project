{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca013f71",
   "metadata": {},
   "source": [
    "## Trying the model on images from the supervisor file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b21c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURACJA ---\n",
    "# Lista Twoich folderów, gdzie masz wymieszane zdjęcia i txt\n",
    "source_folders = [\n",
    "    r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\cams_nov\\sprogoe\\2025-11-22\",\n",
    "    r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\cams_nov\\storebaelt_east\\2025-11-22\"\n",
    "]\n",
    "\n",
    "# Gdzie ma powstać nowy, uporządkowany dataset?\n",
    "dest_root = r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_fixed\"\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def prepare_data():\n",
    "    img_dest = Path(dest_root) / \"images\" / \"val\"\n",
    "    lbl_dest = Path(dest_root) / \"labels\" / \"val\"\n",
    "\n",
    "    # Tworzymy foldery\n",
    "    img_dest.mkdir(parents=True, exist_ok=True)\n",
    "    lbl_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Tworzenie datasetu w: {dest_root}\")\n",
    "\n",
    "    total_imgs = 0\n",
    "    total_lbls = 0\n",
    "\n",
    "    for src in source_folders:\n",
    "        src_path = Path(src)\n",
    "        if not src_path.exists():\n",
    "            print(f\"BŁĄD: Folder nie istnieje: {src}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Przetwarzanie: {src}...\")\n",
    "        \n",
    "        # Pobieramy wszystkie pliki\n",
    "        files = list(src_path.glob(\"*\"))\n",
    "        \n",
    "        for f in files:\n",
    "            if f.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                # Kopiuj zdjęcie\n",
    "                shutil.copy2(f, img_dest / f.name)\n",
    "                total_imgs += 1\n",
    "            elif f.suffix.lower() == '.txt':\n",
    "                # Kopiuj etykietę\n",
    "                shutil.copy2(f, lbl_dest / f.name)\n",
    "                total_lbls += 1\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Gotowe!\")\n",
    "    print(f\"Skopiowano zdjęć: {total_imgs}\")\n",
    "    print(f\"Skopiowano etykiet: {total_lbls}\")\n",
    "    \n",
    "    # Tworzenie nowego pliku YAML\n",
    "    yaml_content = f\"\"\"\n",
    "path: {dest_root}\n",
    "train: images/val  # Używamy val też jako train, jeśli chcesz tylko testować\n",
    "val: images/val\n",
    "names:\n",
    "  0: ship\n",
    "\"\"\"\n",
    "    yaml_path = Path(dest_root) / \"data_fixed.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"\\nStworzono nowy plik konfiguracyjny: {yaml_path}\")\n",
    "    print(\"Użyj tego pliku do walidacji!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c57527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"C:\\\\Users\\\\szymo\\\\Desktop\\\\DTU\\\\3rd_semester\\\\Individual_project_demo\\\\runs\\\\detect\\\\finetune_night_ships\\\\weights\\\\best.pt\")\n",
    "\n",
    "# Wskazujemy na nowy plik YAML stworzony przez skrypt wyżej\n",
    "model.val(data=r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_only_ships\\data_only_ships.yaml\", split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748062ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURACJA ---\n",
    "source_root = Path(r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_fixed\")\n",
    "dest_root = Path(r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_split_70_20_10\")\n",
    "# --------------------\n",
    "\n",
    "def split_and_filter_dataset():\n",
    "    # 1. Czyszczenie folderu docelowego (żeby nie mieszać ze starymi próbami)\n",
    "    if dest_root.exists():\n",
    "        print(\"Usuwam stary folder docelowy, żeby zrobić czysty podział...\")\n",
    "        shutil.rmtree(dest_root)\n",
    "    \n",
    "    # 2. Zbieranie wszystkich poprawnych par (zdjęcie + label ze statkiem)\n",
    "    print(\"Zbieranie danych z folderu źródłowego...\")\n",
    "    src_labels_dir = source_root / \"labels\"\n",
    "    src_images_dir = source_root / \"images\"\n",
    "    \n",
    "    valid_pairs = [] # Lista tupli: (ścieżka_do_label, ścieżka_do_img)\n",
    "\n",
    "    # Szukamy wszystkich plików .txt w źródle (rekurencyjnie, nieważne czy są w train/val/test)\n",
    "    for label_file in src_labels_dir.rglob(\"*.txt\"):\n",
    "        \n",
    "        # Sprawdzamy czy plik NIE jest pusty (czy ma statek)\n",
    "        has_content = False\n",
    "        with open(label_file, 'r') as f:\n",
    "            if any(line.strip() for line in f):\n",
    "                has_content = True\n",
    "        \n",
    "        if has_content:\n",
    "            # Szukamy odpowiadającego zdjęcia\n",
    "            # Musimy zgadnąć gdzie jest zdjęcie, bo struktura folderów images zazwyczaj odpowiada labels\n",
    "            # Sztuczka: podmieniamy w ścieżce \"labels\" na \"images\" i szukamy pliku\n",
    "            \n",
    "            # Pobieramy relatywną ścieżkę pliku txt względem folderu labels\n",
    "            # np. jeśli plik to .../labels/train/plik.txt, to relative to \"train/plik.txt\"\n",
    "            rel_path = label_file.relative_to(src_labels_dir)\n",
    "            \n",
    "            image_found = None\n",
    "            # Szukamy zdjęcia w analogicznym podfolderze w images\n",
    "            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                possible_img_path = src_images_dir / rel_path.with_suffix(ext)\n",
    "                if possible_img_path.exists():\n",
    "                    image_found = possible_img_path\n",
    "                    break\n",
    "            \n",
    "            if image_found:\n",
    "                valid_pairs.append((label_file, image_found))\n",
    "\n",
    "    print(f\"Znaleziono łącznie {len(valid_pairs)} zdjęć ze statkami.\")\n",
    "    \n",
    "    if len(valid_pairs) == 0:\n",
    "        print(\"Błąd: Nie znaleziono żadnych danych! Sprawdź ścieżki.\")\n",
    "        return\n",
    "\n",
    "    # 3. Mieszanie i dzielenie (70% / 20% / 10%)\n",
    "    random.seed(42) # Żeby zawsze dzieliło tak samo\n",
    "    random.shuffle(valid_pairs)\n",
    "\n",
    "    total = len(valid_pairs)\n",
    "    train_end = int(total * 0.70)\n",
    "    val_end = int(total * 0.90) # 70% + 20% = 90%\n",
    "\n",
    "    train_set = valid_pairs[:train_end]\n",
    "    val_set = valid_pairs[train_end:val_end]\n",
    "    test_set = valid_pairs[val_end:]\n",
    "\n",
    "    print(f\"Podział: Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n",
    "\n",
    "    # 4. Funkcja kopiująca\n",
    "    def copy_files(dataset, split_name):\n",
    "        dst_img_dir = dest_root / \"images\" / split_name\n",
    "        dst_lbl_dir = dest_root / \"labels\" / split_name\n",
    "        dst_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for lbl_src, img_src in dataset:\n",
    "            shutil.copy2(lbl_src, dst_lbl_dir / lbl_src.name)\n",
    "            shutil.copy2(img_src, dst_img_dir / img_src.name)\n",
    "\n",
    "    # Kopiujemy fizycznie pliki\n",
    "    print(\"Kopiowanie plików (to chwilę potrwa)...\")\n",
    "    copy_files(train_set, \"train\")\n",
    "    copy_files(val_set, \"val\")\n",
    "    copy_files(test_set, \"test\")\n",
    "\n",
    "    # 5. Tworzenie YAML\n",
    "    yaml_content = f\"\"\"\n",
    "path: {dest_root.as_posix()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: ship\n",
    "\"\"\"\n",
    "    yaml_path = dest_root / \"data_split.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"GOTOWE!\")\n",
    "    print(f\"Nowy dataset jest tu: {dest_root}\")\n",
    "    print(f\"Plik YAML do treningu: {yaml_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_filter_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURACJA ---\n",
    "json_file = 'cams_nov/_annotations.coco.json'\n",
    "image_folders = [\n",
    "    'cams_nov/sprogoe/2025-11-22', \n",
    "    'cams_nov/storebaelt_east/2025-11-22'\n",
    "] \n",
    "# --------------------\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Czyści nazwę pliku do gołego ciągu znaków (tylko litery i cyfry).\n",
    "    Naprawia problem Roboflow z doklejaniem '_jpg' do nazwy.\n",
    "    \"\"\"\n",
    "    name = os.path.basename(name)\n",
    "    \n",
    "    # 1. Usuwamy hash Roboflow (wszystko po .rf.)\n",
    "    name = re.split(r'\\.rf\\.', name)[0]\n",
    "    \n",
    "    # 2. Usuwamy prawdziwe rozszerzenie\n",
    "    name = os.path.splitext(name)[0]\n",
    "    \n",
    "    # 3. KLUCZOWA POPRAWKA: Usuwamy doklejone rozszerzenia w nazwie (np. _jpg, _jpeg)\n",
    "    # Flaga IGNORECASE pozwala łapać JPG, jpg, Jpg itd.\n",
    "    name = re.sub(r'(_jpg|_jpeg|_png)$', '', name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r'(jpg|jpeg|png)$', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    # 4. Zamieniamy wszystko co nie jest cyfrą lub literą na pusty ciąg\n",
    "    # Usuwamy myślniki, dwukropki, podkreślniki, kropki\n",
    "    clean_name = re.sub(r'[^a-zA-Z0-9]', '', name)\n",
    "    \n",
    "    return clean_name\n",
    "\n",
    "def convert_coco_to_yolo_smart():\n",
    "    print(f\"Katalog roboczy skryptu: {os.getcwd()}\")\n",
    "    \n",
    "    # 1. Skanowanie dysku\n",
    "    print(\"Skanowanie plików na dysku...\")\n",
    "    disk_file_map = {} \n",
    "    \n",
    "    total_files_found = 0\n",
    "    for folder in image_folders:\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"❌ BŁĄD: Folder nie istnieje: '{folder}'\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   Przeszukiwanie: {folder}...\")\n",
    "        for f in os.listdir(folder):\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                norm = normalize_name(f)\n",
    "                full_path = os.path.join(folder, f)\n",
    "                disk_file_map[norm] = full_path\n",
    "                total_files_found += 1\n",
    "    \n",
    "    print(f\"✅ Znaleziono łącznie {total_files_found} zdjęć w folderach.\")\n",
    "    if total_files_found == 0:\n",
    "        print(\"❌ BŁĄD KRYTYCZNY: Nie znaleziono żadnych zdjęć.\")\n",
    "        return\n",
    "\n",
    "    # 2. Wczytujemy JSON\n",
    "    if not os.path.exists(json_file):\n",
    "        print(f\"❌ BŁĄD: Nie znaleziono pliku adnotacji: {json_file}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ BŁĄD przy otwieraniu JSON: {e}\")\n",
    "        return\n",
    "\n",
    "    # Mapowanie kategorii\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    sorted_ids = sorted(categories.keys())\n",
    "    id_map = {original_id: new_id for new_id, original_id in enumerate(sorted_ids)}\n",
    "    \n",
    "    print(\"\\nMapowanie klas (COCO -> YOLO):\")\n",
    "    for original, new in id_map.items():\n",
    "        print(f\"  ID {original} ('{categories[original]}') -> ID {new}\")\n",
    "\n",
    "    # 3. Generowanie\n",
    "    print(\"\\nRozpoczynam dopasowywanie i tworzenie .txt...\")\n",
    "    \n",
    "    images_info = {img['id']: img for img in data['images']}\n",
    "    \n",
    "    annotations_by_image = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] = []\n",
    "        annotations_by_image[img_id].append(ann)\n",
    "\n",
    "    processed_count = 0\n",
    "    matched_count = 0\n",
    "    \n",
    "    for img_id, anns in annotations_by_image.items():\n",
    "        img_data = images_info[img_id]\n",
    "        json_filename = img_data['file_name']\n",
    "        \n",
    "        # Normalizacja nazwy z JSON\n",
    "        json_norm = normalize_name(json_filename)\n",
    "        \n",
    "        # PRÓBA DOPASOWANIA\n",
    "        real_path = disk_file_map.get(json_norm)\n",
    "        \n",
    "        if not real_path:\n",
    "            # Debugowanie (pokazujemy to tylko 3 razy żeby nie spamować)\n",
    "            if processed_count < 3: \n",
    "                print(f\"⚠️ DEBUG BRAKU:\")\n",
    "                print(f\"   JSON (czysty): '{json_norm}' (z '{json_filename}')\")\n",
    "                # Próbujemy znaleźć coś podobnego na dysku dla porównania\n",
    "                similar = [k for k in list(disk_file_map.keys())[:500] if json_norm[:10] in k]\n",
    "                if similar:\n",
    "                     print(f\"   Najbardziej podobny na dysku: '{similar[0]}'\")\n",
    "                else:\n",
    "                     print(f\"   Brak podobnych plików na dysku (sprawdzono pierwsze 500).\")\n",
    "            processed_count += 1\n",
    "            continue\n",
    "\n",
    "        matched_count += 1\n",
    "        img_w = img_data['width']\n",
    "        img_h = img_data['height']\n",
    "        \n",
    "        txt_path = os.path.splitext(real_path)[0] + \".txt\"\n",
    "        \n",
    "        with open(txt_path, 'w') as out_f:\n",
    "            for ann in anns:\n",
    "                bbox = ann['bbox'] \n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                x_center = (x + w / 2) / img_w\n",
    "                y_center = (y + h / 2) / img_h\n",
    "                w_norm = w / img_w\n",
    "                h_norm = h / img_h\n",
    "                \n",
    "                x_center = max(0, min(1, x_center))\n",
    "                y_center = max(0, min(1, y_center))\n",
    "                w_norm = max(0, min(1, w_norm))\n",
    "                h_norm = max(0, min(1, h_norm))\n",
    "\n",
    "                class_id = id_map[ann['category_id']]\n",
    "                out_f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "    \n",
    "    print(f\"\\n--- PODSUMOWANIE ---\")\n",
    "    print(f\"Liczba zdjęć w JSON: {len(annotations_by_image)}\")\n",
    "    print(f\"✅ SUKCES: Utworzono pliki .txt dla: {matched_count} zdjęć\")\n",
    "    print(f\"❌ BRAK: Nie dopasowano: {len(annotations_by_image) - matched_count}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_coco_to_yolo_smart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wczytaj swój obecny najlepszy model (żeby kontynuować naukę, a nie zaczynać od zera)\n",
    "# Upewnij się, że ścieżka do best.pt jest poprawna\n",
    "model = YOLO('runs/detect/train4/weights/best.pt') \n",
    "\n",
    "# 2. Odpal dotrenowanie na wyczyszczonym zestawie (tylko zdjęcia ze statkami)\n",
    "model.train(\n",
    "    data=r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_only_ships\\data_only_ships.yaml\",\n",
    "    epochs=10,        # 50 epok spokojnie wystarczy na \"doszlifowanie\"\n",
    "    imgsz=1280,\n",
    "    batch=16,\n",
    "    name='finetune_night_ships'  # Pod taką nazwą zapisze się wynik\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KONFIGURACJA ---\n",
    "source_root = Path(r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_fixed\")\n",
    "dest_root = Path(r\"c:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\dataset_split_70_20_10\")\n",
    "# --------------------\n",
    "\n",
    "def split_and_filter_dataset():\n",
    "    # 1. Czyszczenie folderu docelowego (żeby nie mieszać ze starymi próbami)\n",
    "    if dest_root.exists():\n",
    "        print(\"Usuwam stary folder docelowy, żeby zrobić czysty podział...\")\n",
    "        shutil.rmtree(dest_root)\n",
    "    \n",
    "    # 2. Zbieranie wszystkich poprawnych par (zdjęcie + label ze statkiem)\n",
    "    print(\"Zbieranie danych z folderu źródłowego...\")\n",
    "    src_labels_dir = source_root / \"labels\"\n",
    "    src_images_dir = source_root / \"images\"\n",
    "    \n",
    "    valid_pairs = [] # Lista tupli: (ścieżka_do_label, ścieżka_do_img)\n",
    "\n",
    "    # Szukamy wszystkich plików .txt w źródle (rekurencyjnie, nieważne czy są w train/val/test)\n",
    "    for label_file in src_labels_dir.rglob(\"*.txt\"):\n",
    "        \n",
    "        # Sprawdzamy czy plik NIE jest pusty (czy ma statek)\n",
    "        has_content = False\n",
    "        with open(label_file, 'r') as f:\n",
    "            if any(line.strip() for line in f):\n",
    "                has_content = True\n",
    "        \n",
    "        if has_content:\n",
    "            # Szukamy odpowiadającego zdjęcia\n",
    "            # Musimy zgadnąć gdzie jest zdjęcie, bo struktura folderów images zazwyczaj odpowiada labels\n",
    "            # Sztuczka: podmieniamy w ścieżce \"labels\" na \"images\" i szukamy pliku\n",
    "            \n",
    "            # Pobieramy relatywną ścieżkę pliku txt względem folderu labels\n",
    "            # np. jeśli plik to .../labels/train/plik.txt, to relative to \"train/plik.txt\"\n",
    "            rel_path = label_file.relative_to(src_labels_dir)\n",
    "            \n",
    "            image_found = None\n",
    "            # Szukamy zdjęcia w analogicznym podfolderze w images\n",
    "            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                possible_img_path = src_images_dir / rel_path.with_suffix(ext)\n",
    "                if possible_img_path.exists():\n",
    "                    image_found = possible_img_path\n",
    "                    break\n",
    "            \n",
    "            if image_found:\n",
    "                valid_pairs.append((label_file, image_found))\n",
    "\n",
    "    print(f\"Znaleziono łącznie {len(valid_pairs)} zdjęć ze statkami.\")\n",
    "    \n",
    "    if len(valid_pairs) == 0:\n",
    "        print(\"Błąd: Nie znaleziono żadnych danych! Sprawdź ścieżki.\")\n",
    "        return\n",
    "\n",
    "    # 3. Mieszanie i dzielenie (70% / 20% / 10%)\n",
    "    random.seed(42) # Żeby zawsze dzieliło tak samo\n",
    "    random.shuffle(valid_pairs)\n",
    "\n",
    "    total = len(valid_pairs)\n",
    "    train_end = int(total * 0.70)\n",
    "    val_end = int(total * 0.90) # 70% + 20% = 90%\n",
    "\n",
    "    train_set = valid_pairs[:train_end]\n",
    "    val_set = valid_pairs[train_end:val_end]\n",
    "    test_set = valid_pairs[val_end:]\n",
    "\n",
    "    print(f\"Podział: Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n",
    "\n",
    "    # 4. Funkcja kopiująca\n",
    "    def copy_files(dataset, split_name):\n",
    "        dst_img_dir = dest_root / \"images\" / split_name\n",
    "        dst_lbl_dir = dest_root / \"labels\" / split_name\n",
    "        dst_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for lbl_src, img_src in dataset:\n",
    "            shutil.copy2(lbl_src, dst_lbl_dir / lbl_src.name)\n",
    "            shutil.copy2(img_src, dst_img_dir / img_src.name)\n",
    "\n",
    "    # Kopiujemy fizycznie pliki\n",
    "    print(\"Kopiowanie plików (to chwilę potrwa)...\")\n",
    "    copy_files(train_set, \"train\")\n",
    "    copy_files(val_set, \"val\")\n",
    "    copy_files(test_set, \"test\")\n",
    "\n",
    "    # 5. Tworzenie YAML\n",
    "    yaml_content = f\"\"\"\n",
    "path: {dest_root.as_posix()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: ship\n",
    "\"\"\"\n",
    "    yaml_path = dest_root / \"data_split.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"GOTOWE!\")\n",
    "    print(f\"Nowy dataset jest tu: {dest_root}\")\n",
    "    print(f\"Plik YAML do treningu: {yaml_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_filter_dataset()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
