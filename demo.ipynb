{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b59203c",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9ce81",
   "metadata": {},
   "source": [
    "# 2. Merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836f21f",
   "metadata": {},
   "source": [
    "## Seaship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a251434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'sea_ship/seaship.v1i.yolov8/test/images'\n",
    "source_1 = 'sea_ship/seaship.v1i.yolov8/train/images'\n",
    "destination = 'merged_dataset/images'\n",
    "\n",
    "# gather all files\n",
    "allfiles = os.listdir(source)\n",
    "allfiles_1 = os.listdir(source_1)\n",
    "\n",
    "# iterate on all files to move them to destination folder\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(source, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_1:\n",
    "    src_path = os.path.join(source_1, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d7ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_labels = 'sea_ship/seaship.v1i.yolov8/test/labels'\n",
    "source_1_labels = 'sea_ship/seaship.v1i.yolov8/train/labels'\n",
    "destination = 'merged_dataset/labels'\n",
    "\n",
    "# gather all files\n",
    "allfiles = os.listdir(source_labels)\n",
    "allfiles_1 = os.listdir(source_1_labels)\n",
    "\n",
    "# iterate on all files to move them to destination folder\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(source_labels, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_1:\n",
    "    src_path = os.path.join(source_1_labels, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade91436",
   "metadata": {},
   "source": [
    "## Singapore Maritime Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc02e84",
   "metadata": {},
   "source": [
    "### Replacing numbering of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f4eaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0: 6, 1: 7, 2: 8, 3: 9, 4: 10, 5: 11, 6: 12, 7: 13, 8: 14}\n",
    "\n",
    "input_dir = \"Singapore maritime.v5i.yolov8/valid/labels\"\n",
    "output_dir = \"Singapore maritime.v5i.yolov8/valid/labels_new\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(input_dir, filename), 'r') as f_in, \\\n",
    "             open(os.path.join(output_dir, filename), 'w') as f_out:\n",
    "            for line in f_in:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    old_class = int(parts[0])\n",
    "                    new_class = class_mapping.get(old_class, old_class)\n",
    "                    parts[0] = str(new_class)\n",
    "                    f_out.write(' '.join(parts) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7945d",
   "metadata": {},
   "source": [
    "## Moving the images and labels to the desired location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162e8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"Singapore maritime.v5i.yolov8/train/images\"\n",
    "source_1 = \"Singapore maritime.v5i.yolov8/valid/images\"\n",
    "source_2 = \"Singapore maritime.v5i.yolov8/test/images\"\n",
    "destination = \"merged_dataset/images\"\n",
    "\n",
    "# gather all files\n",
    "allfiles = os.listdir(source)\n",
    "allfiles_1 = os.listdir(source_1)\n",
    "allfiles_2 = os.listdir(source_2)\n",
    "\n",
    "# iterate on all files to move them to destination folder\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(source, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_1:\n",
    "    src_path = os.path.join(source_1, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_2:\n",
    "    src_path = os.path.join(source_2, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c465ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Nie można utworzyć pliku, który już istnieje: 'Singapore maritime.v5i.yolov8/valid/labels_new\\\\MVI_0790_VIS_OB_frame105_jpg.rf.2af8bd6af1d1ce31772ecbb60f870710.txt' -> 'merged_dataset/labels\\\\MVI_0790_VIS_OB_frame105_jpg.rf.2af8bd6af1d1ce31772ecbb60f870710.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_1, f)\n\u001b[0;32m     19\u001b[0m     dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination, f)\n\u001b[1;32m---> 20\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src_path, dst_path)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m allfiles_2:\n\u001b[0;32m     23\u001b[0m     src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_2, f)\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Nie można utworzyć pliku, który już istnieje: 'Singapore maritime.v5i.yolov8/valid/labels_new\\\\MVI_0790_VIS_OB_frame105_jpg.rf.2af8bd6af1d1ce31772ecbb60f870710.txt' -> 'merged_dataset/labels\\\\MVI_0790_VIS_OB_frame105_jpg.rf.2af8bd6af1d1ce31772ecbb60f870710.txt'"
     ]
    }
   ],
   "source": [
    "source = \"Singapore maritime.v5i.yolov8/train/labels_new\"\n",
    "source_1 = \"Singapore maritime.v5i.yolov8/valid/labels_new\"\n",
    "source_2 = \"Singapore maritime.v5i.yolov8/test/labels_new\"\n",
    "destination = \"merged_dataset/labels\"\n",
    "\n",
    "# gather all files\n",
    "allfiles = os.listdir(source)\n",
    "allfiles_1 = os.listdir(source_1)\n",
    "allfiles_2 = os.listdir(source_2)\n",
    "\n",
    "# iterate on all files to move them to destination folder\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(source, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_1:\n",
    "    src_path = os.path.join(source_1, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)\n",
    "\n",
    "for f in allfiles_2:\n",
    "    src_path = os.path.join(source_2, f)\n",
    "    dst_path = os.path.join(destination, f)\n",
    "    os.rename(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0387cc5",
   "metadata": {},
   "source": [
    "# 2. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f5303",
   "metadata": {},
   "source": [
    "## Building up the dataframe w/ current files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47da2922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total label files scanned: 13329\n",
      "Total bounding boxes (rows): 57515\n",
      "Empty label files: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>class</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001_jpg.rf.a030cdccc38ea75b40886ab22a6bb414...</td>\n",
       "      <td>000001_jpg.rf.a030cdccc38ea75b40886ab22a6bb414...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.451389</td>\n",
       "      <td>0.161979</td>\n",
       "      <td>0.039815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002_jpg.rf.f34ffd48a87c63f8dd719db1caafe9de...</td>\n",
       "      <td>000002_jpg.rf.f34ffd48a87c63f8dd719db1caafe9de...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.461574</td>\n",
       "      <td>0.186458</td>\n",
       "      <td>0.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003_jpg.rf.6c421cbf23a578007341ba53c456e29e...</td>\n",
       "      <td>000003_jpg.rf.6c421cbf23a578007341ba53c456e29e...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54401</td>\n",
       "      <td>0.459722</td>\n",
       "      <td>0.183854</td>\n",
       "      <td>0.043519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004_jpg.rf.575252f879c2e9a9936a8fcea7442c29...</td>\n",
       "      <td>000004_jpg.rf.575252f879c2e9a9936a8fcea7442c29...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005_jpg.rf.40de319875226569bd91d448d071c2db...</td>\n",
       "      <td>000005_jpg.rf.40de319875226569bd91d448d071c2db...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.809115</td>\n",
       "      <td>0.499074</td>\n",
       "      <td>0.166146</td>\n",
       "      <td>0.042593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000006_jpg.rf.7ed6bb3399639d916d897014c842484c...</td>\n",
       "      <td>000006_jpg.rf.7ed6bb3399639d916d897014c842484c...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.178125</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000007_jpg.rf.34d08bc4f25858287a291f52dd5f4725...</td>\n",
       "      <td>000007_jpg.rf.34d08bc4f25858287a291f52dd5f4725...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.634115</td>\n",
       "      <td>0.469907</td>\n",
       "      <td>0.222396</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000008_jpg.rf.200d753625fd61bb308c95e804144e49...</td>\n",
       "      <td>000008_jpg.rf.200d753625fd61bb308c95e804144e49...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.205208</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000009_jpg.rf.f10dbae55ebeda058fa23fefe3fbb25f...</td>\n",
       "      <td>000009_jpg.rf.f10dbae55ebeda058fa23fefe3fbb25f...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.594792</td>\n",
       "      <td>0.465741</td>\n",
       "      <td>0.202083</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000010_jpg.rf.d6e4cc8e2f9cb55462f3ce58a55ef35d...</td>\n",
       "      <td>000010_jpg.rf.d6e4cc8e2f9cb55462f3ce58a55ef35d...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>0.485185</td>\n",
       "      <td>0.339583</td>\n",
       "      <td>0.072222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          label_file  \\\n",
       "0  000001_jpg.rf.a030cdccc38ea75b40886ab22a6bb414...   \n",
       "1  000002_jpg.rf.f34ffd48a87c63f8dd719db1caafe9de...   \n",
       "2  000003_jpg.rf.6c421cbf23a578007341ba53c456e29e...   \n",
       "3  000004_jpg.rf.575252f879c2e9a9936a8fcea7442c29...   \n",
       "4  000005_jpg.rf.40de319875226569bd91d448d071c2db...   \n",
       "5  000006_jpg.rf.7ed6bb3399639d916d897014c842484c...   \n",
       "6  000007_jpg.rf.34d08bc4f25858287a291f52dd5f4725...   \n",
       "7  000008_jpg.rf.200d753625fd61bb308c95e804144e49...   \n",
       "8  000009_jpg.rf.f10dbae55ebeda058fa23fefe3fbb25f...   \n",
       "9  000010_jpg.rf.d6e4cc8e2f9cb55462f3ce58a55ef35d...   \n",
       "\n",
       "                                          image_file class         x  \\\n",
       "0  000001_jpg.rf.a030cdccc38ea75b40886ab22a6bb414...     4  0.410156   \n",
       "1  000002_jpg.rf.f34ffd48a87c63f8dd719db1caafe9de...     4  0.558333   \n",
       "2  000003_jpg.rf.6c421cbf23a578007341ba53c456e29e...     4   0.54401   \n",
       "3  000004_jpg.rf.575252f879c2e9a9936a8fcea7442c29...     4    0.8875   \n",
       "4  000005_jpg.rf.40de319875226569bd91d448d071c2db...     4  0.809115   \n",
       "5  000006_jpg.rf.7ed6bb3399639d916d897014c842484c...     4  0.526042   \n",
       "6  000007_jpg.rf.34d08bc4f25858287a291f52dd5f4725...     4  0.634115   \n",
       "7  000008_jpg.rf.200d753625fd61bb308c95e804144e49...     4  0.615625   \n",
       "8  000009_jpg.rf.f10dbae55ebeda058fa23fefe3fbb25f...     4  0.594792   \n",
       "9  000010_jpg.rf.d6e4cc8e2f9cb55462f3ce58a55ef35d...     4  0.829688   \n",
       "\n",
       "          y         w         h  \n",
       "0  0.451389  0.161979  0.039815  \n",
       "1  0.461574  0.186458  0.047222  \n",
       "2  0.459722  0.183854  0.043519  \n",
       "3  0.505556  0.177083      0.05  \n",
       "4  0.499074  0.166146  0.042593  \n",
       "5  0.460185  0.178125      0.05  \n",
       "6  0.469907  0.222396  0.058333  \n",
       "7  0.466667  0.205208  0.055556  \n",
       "8  0.465741  0.202083      0.05  \n",
       "9  0.485185  0.339583  0.072222  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing label .txt files\n",
    "labels_dir = 'merged_dataset/labels'\n",
    "files = sorted(glob.glob(os.path.join(labels_dir, '*.txt')))\n",
    "\n",
    "rows = []\n",
    "if not files:\n",
    "    # No label files found: create an empty dataframe with expected columns\n",
    "    print('No label files found in', labels_dir)\n",
    "    labels_df = pd.DataFrame(columns=['label_file', 'image_file', 'class', 'x', 'y', 'w', 'h'])\n",
    "else:\n",
    "    for fp in files:\n",
    "        basename = os.path.basename(fp)\n",
    "        image_name = os.path.splitext(basename)[0] + '.jpg'\n",
    "        # read non-empty lines\n",
    "        with open(fp, 'r', encoding='utf-8') as f:\n",
    "            lines = [ln.strip() for ln in f.readlines() if ln.strip() != '']\n",
    "        if not lines:\n",
    "            # file had no labels; create one row with NaNs for class and coords\n",
    "            rows.append({\n",
    "                'label_file': basename,\n",
    "                'image_file': image_name,\n",
    "                'class': pd.NA,\n",
    "                'x': pd.NA,\n",
    "                'y': pd.NA,\n",
    "                'w': pd.NA,\n",
    "                'h': pd.NA\n",
    "            })\n",
    "        else:\n",
    "            for ln in lines:\n",
    "                parts = ln.split()\n",
    "                # YOLO format: class x_center y_center width height\n",
    "                try:\n",
    "                    cls = int(parts[0]) if len(parts) >= 1 else pd.NA\n",
    "                except ValueError:\n",
    "                    cls = pd.NA\n",
    "                coords = [pd.NA, pd.NA, pd.NA, pd.NA]\n",
    "                if len(parts) >= 5:\n",
    "                    try:\n",
    "                        coords = [float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])]\n",
    "                    except ValueError:\n",
    "                        coords = [pd.NA, pd.NA, pd.NA, pd.NA]\n",
    "                rows.append({\n",
    "                    'label_file': basename,\n",
    "                    'image_file': image_name,\n",
    "                    'class': cls,\n",
    "                    'x': coords[0],\n",
    "                    'y': coords[1],\n",
    "                    'w': coords[2],\n",
    "                    'h': coords[3],\n",
    "                })\n",
    "    # build dataframe from parsed rows\n",
    "    labels_df = pd.DataFrame(rows)\n",
    "\n",
    "# compute summary stats\n",
    "total_files = len(files)\n",
    "total_boxes = int(labels_df['class'].notna().sum()) if not labels_df.empty else 0\n",
    "empty_label_files = int(labels_df.loc[labels_df['class'].isna(), 'label_file'].nunique()) if not labels_df.empty else 0\n",
    "print(f'Total label files scanned: {total_files}')\n",
    "print(f'Total bounding boxes (rows): {total_boxes}')\n",
    "print(f'Empty label files: {empty_label_files}')\n",
    "\n",
    "# show a sample preview\n",
    "labels_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76797245",
   "metadata": {},
   "source": [
    "## Summing up and plotting the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affbc8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m vals \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     56\u001b[0m x_labels \u001b[38;5;241m=\u001b[39m [class_names\u001b[38;5;241m.\u001b[39mget(i, \u001b[38;5;28mstr\u001b[39m(i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]\n\u001b[1;32m---> 57\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     58\u001b[0m bars \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mbar(x_labels, vals, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtab:blue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Distribution\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Try to load class names from merged_dataset/data.yaml\n",
    "class_names = {}\n",
    "data_yaml_path = 'merged_dataset/data.yaml'\n",
    "if os.path.exists(data_yaml_path):\n",
    "    try:\n",
    "        import yaml\n",
    "        with open(data_yaml_path, 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        names = data.get('names') if isinstance(data, dict) else None\n",
    "        if isinstance(names, dict):\n",
    "            # keys may be strings; convert to ints\n",
    "            class_names = {int(k): v for k, v in names.items()}\n",
    "        elif isinstance(names, list):\n",
    "            class_names = {i: n for i, n in enumerate(names)}\n",
    "    except Exception:\n",
    "        # fallback: simple parse for a YAML 'names' block\n",
    "        try:\n",
    "            with open(data_yaml_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            names_list = []\n",
    "            in_names = False\n",
    "            for ln in lines:\n",
    "                s = ln.strip()\n",
    "                if s.startswith('names:'):\n",
    "                    # might be inline list or start of block\n",
    "                    rest = s.split('names:', 1)[1].strip()\n",
    "                    if rest.startswith('['):\n",
    "                        # literal list, try eval safely\n",
    "                        import ast\n",
    "                        try:\n",
    "                            names_list = ast.literal_eval(rest)\n",
    "                        except Exception:\n",
    "                            names_list = []\n",
    "                        break\n",
    "                    else:\n",
    "                        in_names = True\n",
    "                        continue\n",
    "                if in_names:\n",
    "                    if s.startswith('-'):\n",
    "                        names_list.append(s.lstrip('-').strip().strip('\"'))\n",
    "                    else:\n",
    "                        break\n",
    "            class_names = {i: n for i, n in enumerate(names_list)}\n",
    "        except Exception:\n",
    "            class_names = {}\n",
    "else:\n",
    "    print(f'No data.yaml at {data_yaml_path}; falling back to numeric class IDs')\n",
    "\n",
    "# If labels_df is empty or has no class entries, show message\n",
    "if 'labels_df' not in globals() or labels_df.empty or labels_df['class'].dropna().empty:\n",
    "    print('No labeled bounding boxes to plot.')\n",
    "else:\n",
    "    counts = labels_df['class'].dropna().astype(int).value_counts().sort_index()\n",
    "    idx = list(counts.index)\n",
    "    vals = counts.values\n",
    "    x_labels = [class_names.get(i, str(i)) for i in idx]\n",
    "    plt.figure(figsize=(12,6))\n",
    "    bars = plt.bar(x_labels, vals, color='tab:blue')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.ylabel('Number of bounding boxes')\n",
    "    plt.xlabel('Class')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    # annotate counts on bars\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.annotate(f'{int(h)}', xy=(bar.get_x() + bar.get_width() / 2, h), xytext=(0, 3), textcoords='offset points', ha='center', va='bottom', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765b805",
   "metadata": {},
   "source": [
    "## Creating video with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d788cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6350 images...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 103\u001b[0m\n\u001b[0;32m     97\u001b[0m                 cv2\u001b[38;5;241m.\u001b[39mputText(\n\u001b[0;32m     98\u001b[0m                     img, class_label, (x1, y1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m     99\u001b[0m                     cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    100\u001b[0m                 )\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Write frame to video\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     out\u001b[38;5;241m.\u001b[39mwrite(img)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Release the video writer\u001b[39;00m\n\u001b[0;32m    106\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Paths - adjust these to your setup\n",
    "images_dir = \"merged_dataset/images\"\n",
    "labels_dir = \"merged_dataset/labels\"\n",
    "output_video = \"ground_truth_video_singapore_maritime.mp4\"\n",
    "\n",
    "# Class names dictionary (adjust based on your dataset)\n",
    "class_names = {\n",
    "    0: \"bulk cargo carrier\",\n",
    "    1: \"container ship\",\n",
    "    2: \"fishing boat\",\n",
    "    3: \"general cargo ship\",\n",
    "    4: \"ore carrier\",\n",
    "    5: \"passenger ship\",\n",
    "    6: \"Boat\",\n",
    "    7: \"Buoy\",\n",
    "    8: \"Ferry\",\n",
    "    9: \"Flying bird-plane\",\n",
    "    10: \"Kayak\",\n",
    "    11: \"Other\",\n",
    "    12: \"Sail boat\",\n",
    "    13: \"Speed boat\",\n",
    "    14: \"Vessel-ship\",\n",
    "}\n",
    "\n",
    "# Filter only Singapore Maritime dataset images (they start with 'MVI')\n",
    "image_files = sorted(glob.glob(os.path.join(images_dir, \"MVI*.jpg\")))\n",
    "# Try other extensions if needed\n",
    "if not image_files:\n",
    "    image_files = sorted(glob.glob(os.path.join(images_dir, \"MVI*.png\")))\n",
    "\n",
    "# Check if we found any images\n",
    "if not image_files:\n",
    "    print(\"No Singapore Maritime dataset images found!\")\n",
    "else:\n",
    "    # Read first image to get dimensions\n",
    "    first_img = cv2.imread(image_files[0])\n",
    "    height, width = first_img.shape[:2]\n",
    "    \n",
    "    # Define the output video writer using mp4v codec, 30fps\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, 30.0, (width, height))\n",
    "    \n",
    "    # Process each image\n",
    "    print(f\"Processing {len(image_files)} images...\")\n",
    "    \n",
    "    for idx, img_path in enumerate(image_files):\n",
    "        # Print progress message\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(image_files)} images\")\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Skip if image couldn't be loaded\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Get corresponding label file\n",
    "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(labels_dir, f\"{img_name}.txt\")\n",
    "        \n",
    "        # Get all bounding boxes for this image\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    \n",
    "                    # Skip if no class information\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    \n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, box_width, box_height = map(\n",
    "                        float, parts[1:5]\n",
    "                    )\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x_center_px = int(x_center * width)\n",
    "                    y_center_px = int(y_center * height)\n",
    "                    box_width_px = int(box_width * width)\n",
    "                    box_height_px = int(box_height * height)\n",
    "                    \n",
    "                    # Calculate the corner points from center, width, height\n",
    "                    x1 = int(x_center_px - box_width_px / 2)\n",
    "                    y1 = int(y_center_px - box_height_px / 2)\n",
    "                    x2 = int(x_center_px + box_width_px / 2)\n",
    "                    y2 = int(y_center_px + box_height_px / 2)\n",
    "                    \n",
    "                    # Draw rectangle (green color)\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Get class name if available from the class_names dict\n",
    "                    class_label = class_names.get(class_id, f\"Class_{class_id}\")\n",
    "                    \n",
    "                    # Put class name text above the box\n",
    "                    cv2.putText(\n",
    "                        img, class_label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2\n",
    "                    )\n",
    "        \n",
    "        # Write frame to video\n",
    "        out.write(img)\n",
    "    \n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "    #print(f\"Video saved to {output_video}\")\n",
    "    #print(f\"Total frames: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3d95d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ID: 0, Class Name: bulk cargo carrier\n",
      "Class ID: 1, Class Name: container ship\n",
      "Class ID: 2, Class Name: fishing boat\n",
      "Class ID: 3, Class Name: general cargo ship\n",
      "Class ID: 4, Class Name: ore carrier\n",
      "Class ID: 5, Class Name: passenger ship\n",
      "Class ID: 6, Class Name: Boat\n",
      "Class ID: 7, Class Name: Buoy\n",
      "Class ID: 8, Class Name: Ferry\n",
      "Class ID: 9, Class Name: Flying bird-plane\n",
      "Class ID: 10, Class Name: Kayak\n",
      "Class ID: 11, Class Name: Other\n",
      "Class ID: 12, Class Name: Sail boat\n",
      "Class ID: 13, Class Name: Speed boat\n",
      "Class ID: 14, Class Name: Vessel-ship\n"
     ]
    }
   ],
   "source": [
    "for label, label_name in class_names.items():\n",
    "    print(f\"Class ID: {label}, Class Name: {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb5e5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szymo\\AppData\\Local\\Temp\\ipykernel_18344\\2062472196.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  labels_df['class'].replace({4:1, 5:1, 1:1, 0:1, 3:1, 2:1, 14:1, 6:1, 13:1, 8:1, 12:1, 10:1}, inplace=True)\n",
      "C:\\Users\\szymo\\AppData\\Local\\Temp\\ipykernel_18344\\2062472196.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  labels_df['class'].replace({4:1, 5:1, 1:1, 0:1, 3:1, 2:1, 14:1, 6:1, 13:1, 8:1, 12:1, 10:1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "labels_df = labels_df.loc[(labels_df['class'] != 7) & (labels_df['class'] != 9) & (labels_df['class'] != 11) & (labels_df['class'].notna())]\n",
    "labels_df['class'].replace({4:1, 5:1, 1:1, 0:1, 3:1, 2:1, 14:1, 6:1, 13:1, 8:1, 12:1, 10:1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e7a8b",
   "metadata": {},
   "source": [
    "# Image preparation for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981a808",
   "metadata": {},
   "source": [
    "## Dividing data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53837bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35085, 7), (10075, 7), (4962, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = labels_df.sample(frac=0.7, random_state=42)\n",
    "\n",
    "# Dropping all those indexes from the dataframe that exists in the train_set\n",
    "test_set = labels_df.drop(train_set.index)\n",
    "train_set.shape, test_set.shape\n",
    "\n",
    "valid_set = test_set.sample(frac=0.33, random_state=42)\n",
    "test_set = test_set.drop(valid_set.index)\n",
    "train_set.shape, test_set.shape, valid_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcae1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_file</th>\n",
       "      <th>image_file</th>\n",
       "      <th>class</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19363</th>\n",
       "      <td>MVI_1484_VIS_frame520_jpg.rf.758df4867230027fb...</td>\n",
       "      <td>MVI_1484_VIS_frame520_jpg.rf.758df4867230027fb...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974479</td>\n",
       "      <td>0.20463</td>\n",
       "      <td>0.051042</td>\n",
       "      <td>0.272222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>MVI_1463_NIR_frame235_jpg.rf.64631fa71c521cb4b...</td>\n",
       "      <td>MVI_1463_NIR_frame235_jpg.rf.64631fa71c521cb4b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146678</td>\n",
       "      <td>0.601071</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.025415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>MVI_1486_VIS_frame255_jpg.rf.e248089552897fa25...</td>\n",
       "      <td>MVI_1486_VIS_frame255_jpg.rf.e248089552897fa25...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033601</td>\n",
       "      <td>0.283719</td>\n",
       "      <td>0.06268</td>\n",
       "      <td>0.055075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36283</th>\n",
       "      <td>MVI_1582_VIS_frame290_jpg.rf.1768de29838256e56...</td>\n",
       "      <td>MVI_1582_VIS_frame290_jpg.rf.1768de29838256e56...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641921</td>\n",
       "      <td>0.615552</td>\n",
       "      <td>0.383354</td>\n",
       "      <td>0.15805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>002375_jpg.rf.1dfdd8637f42e46a253ba90a17222a51...</td>\n",
       "      <td>002375_jpg.rf.1dfdd8637f42e46a253ba90a17222a51...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332552</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.665104</td>\n",
       "      <td>0.161111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51502</th>\n",
       "      <td>MVI_1624_VIS_frame300_jpg.rf.9cd127efca4ec8893...</td>\n",
       "      <td>MVI_1624_VIS_frame300_jpg.rf.9cd127efca4ec8893...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514149</td>\n",
       "      <td>0.503379</td>\n",
       "      <td>0.022334</td>\n",
       "      <td>0.03074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18834</th>\n",
       "      <td>MVI_1482_VIS_frame365_jpg.rf.945f8946b8343f7f9...</td>\n",
       "      <td>MVI_1482_VIS_frame365_jpg.rf.945f8946b8343f7f9...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520547</td>\n",
       "      <td>0.364466</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.025781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40936</th>\n",
       "      <td>MVI_1592_VIS_frame105_jpg.rf.84811d72e3ea56e6e...</td>\n",
       "      <td>MVI_1592_VIS_frame105_jpg.rf.84811d72e3ea56e6e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480824</td>\n",
       "      <td>0.476558</td>\n",
       "      <td>0.064943</td>\n",
       "      <td>0.032507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52218</th>\n",
       "      <td>MVI_1625_VIS_frame315_jpg.rf.f9c5bf3e6458f3ae1...</td>\n",
       "      <td>MVI_1625_VIS_frame315_jpg.rf.f9c5bf3e6458f3ae1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294499</td>\n",
       "      <td>0.525414</td>\n",
       "      <td>0.016739</td>\n",
       "      <td>0.020702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>MVI_0895_NIR_Haze_frame150_jpg.rf.832b6689ce7b...</td>\n",
       "      <td>MVI_0895_NIR_Haze_frame150_jpg.rf.832b6689ce7b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205659</td>\n",
       "      <td>0.58177</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.044418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35085 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              label_file  \\\n",
       "19363  MVI_1484_VIS_frame520_jpg.rf.758df4867230027fb...   \n",
       "13243  MVI_1463_NIR_frame235_jpg.rf.64631fa71c521cb4b...   \n",
       "19930  MVI_1486_VIS_frame255_jpg.rf.e248089552897fa25...   \n",
       "36283  MVI_1582_VIS_frame290_jpg.rf.1768de29838256e56...   \n",
       "3016   002375_jpg.rf.1dfdd8637f42e46a253ba90a17222a51...   \n",
       "...                                                  ...   \n",
       "51502  MVI_1624_VIS_frame300_jpg.rf.9cd127efca4ec8893...   \n",
       "18834  MVI_1482_VIS_frame365_jpg.rf.945f8946b8343f7f9...   \n",
       "40936  MVI_1592_VIS_frame105_jpg.rf.84811d72e3ea56e6e...   \n",
       "52218  MVI_1625_VIS_frame315_jpg.rf.f9c5bf3e6458f3ae1...   \n",
       "10003  MVI_0895_NIR_Haze_frame150_jpg.rf.832b6689ce7b...   \n",
       "\n",
       "                                              image_file  class         x  \\\n",
       "19363  MVI_1484_VIS_frame520_jpg.rf.758df4867230027fb...      1  0.974479   \n",
       "13243  MVI_1463_NIR_frame235_jpg.rf.64631fa71c521cb4b...      1  0.146678   \n",
       "19930  MVI_1486_VIS_frame255_jpg.rf.e248089552897fa25...      1  0.033601   \n",
       "36283  MVI_1582_VIS_frame290_jpg.rf.1768de29838256e56...      1  0.641921   \n",
       "3016   002375_jpg.rf.1dfdd8637f42e46a253ba90a17222a51...      1  0.332552   \n",
       "...                                                  ...    ...       ...   \n",
       "51502  MVI_1624_VIS_frame300_jpg.rf.9cd127efca4ec8893...      1  0.514149   \n",
       "18834  MVI_1482_VIS_frame365_jpg.rf.945f8946b8343f7f9...      1  0.520547   \n",
       "40936  MVI_1592_VIS_frame105_jpg.rf.84811d72e3ea56e6e...      1  0.480824   \n",
       "52218  MVI_1625_VIS_frame315_jpg.rf.f9c5bf3e6458f3ae1...      1  0.294499   \n",
       "10003  MVI_0895_NIR_Haze_frame150_jpg.rf.832b6689ce7b...      1  0.205659   \n",
       "\n",
       "              y         w         h  \n",
       "19363   0.20463  0.051042  0.272222  \n",
       "13243  0.601071  0.021385  0.025415  \n",
       "19930  0.283719   0.06268  0.055075  \n",
       "36283  0.615552  0.383354   0.15805  \n",
       "3016   0.383333  0.665104  0.161111  \n",
       "...         ...       ...       ...  \n",
       "51502  0.503379  0.022334   0.03074  \n",
       "18834  0.364466  0.052333  0.025781  \n",
       "40936  0.476558  0.064943  0.032507  \n",
       "52218  0.525414  0.016739  0.020702  \n",
       "10003   0.58177  0.032413  0.044418  \n",
       "\n",
       "[35085 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be9475",
   "metadata": {},
   "source": [
    "## Creating folders for train, test, valid splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc1c7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76c3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train_set['image_file'].unique():\n",
    "    src_path = os.path.join('merged_dataset/images', file)\n",
    "    dst_path = os.path.join('final_dataset/train/images', file)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "for file_label in train_set['label_file'].unique():\n",
    "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
    "    dst_path = os.path.join('final_dataset/train/labels', file_label)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "for file in valid_set['image_file'].unique():\n",
    "    src_path = os.path.join('merged_dataset/images', file)\n",
    "    dst_path = os.path.join('final_dataset/valid/images', file)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "for file_label in valid_set['label_file'].unique():\n",
    "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
    "    dst_path = os.path.join('final_dataset/valid/labels', file_label)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "for file in test_set['image_file'].unique():\n",
    "    src_path = os.path.join('merged_dataset/images', file)\n",
    "    dst_path = os.path.join('final_dataset/test/images', file)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "for file_label in test_set['label_file'].unique():  \n",
    "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
    "    dst_path = os.path.join('final_dataset/test/labels', file_label)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy2(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707f88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "t = gc.get_threshold()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb1443",
   "metadata": {},
   "source": [
    "## Training the yolo model w/out augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
