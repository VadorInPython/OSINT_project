{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b59203c",
      "metadata": {
        "id": "3b59203c"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068f5469",
      "metadata": {
        "id": "068f5469"
      },
      "outputs": [],
      "source": [
        "# System, file operations, and utilities\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "\n",
        "# Data manipulation and numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Image processing and augmentation\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "# Machine Learning and Computer Vision\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Visualization and Interactive UI (Jupyter/Colab)\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image, clear_output\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed9ce81",
      "metadata": {
        "id": "3ed9ce81"
      },
      "source": [
        "# 2. Merging datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0836f21f",
      "metadata": {
        "id": "0836f21f"
      },
      "source": [
        "## Seaship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a251434e",
      "metadata": {
        "id": "a251434e"
      },
      "outputs": [],
      "source": [
        "source = 'sea_ship/seaship.v1i.yolov8/test/images'\n",
        "source_1 = 'sea_ship/seaship.v1i.yolov8/train/images'\n",
        "destination = 'merged_dataset/images'\n",
        "\n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        "allfiles_1 = os.listdir(source_1)\n",
        "\n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_1:\n",
        "    src_path = os.path.join(source_1, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d7ff17",
      "metadata": {
        "id": "f3d7ff17"
      },
      "outputs": [],
      "source": [
        "source_labels = 'sea_ship/seaship.v1i.yolov8/test/labels'\n",
        "source_1_labels = 'sea_ship/seaship.v1i.yolov8/train/labels'\n",
        "destination = 'merged_dataset/labels'\n",
        "\n",
        "# gather all files\n",
        "allfiles = os.listdir(source_labels)\n",
        "allfiles_1 = os.listdir(source_1_labels)\n",
        "\n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source_labels, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_1:\n",
        "    src_path = os.path.join(source_1_labels, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f81ef3",
      "metadata": {
        "id": "11f81ef3"
      },
      "outputs": [],
      "source": [
        "class_mapping = {i: 0 for i in range(9)}\n",
        "\n",
        "input_dir = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\seaships\\valid\\labels\"\n",
        "output_dir = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\seaships\\valid\\labels_new\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(input_dir, filename), 'r') as f_in, \\\n",
        "             open(os.path.join(output_dir, filename), 'w') as f_out:\n",
        "            for line in f_in:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    old_class = int(parts[0])\n",
        "                    new_class = class_mapping.get(old_class, old_class)\n",
        "                    parts[0] = str(new_class)\n",
        "                    f_out.write(' '.join(parts) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade91436",
      "metadata": {
        "id": "ade91436"
      },
      "source": [
        "## Singapore Maritime Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc02e84",
      "metadata": {
        "id": "1fc02e84"
      },
      "source": [
        "### Replacing numbering of the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4eaf42",
      "metadata": {
        "id": "7f4eaf42"
      },
      "outputs": [],
      "source": [
        "class_mapping = {i: 0 for i in range(20)}\n",
        "\n",
        "input_dir = \"Singapore maritime.v5i.yolov8/test/labels\"\n",
        "output_dir = \"Singapore maritime.v5i.yolov8/test/labels_new\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(input_dir, filename), 'r') as f_in, \\\n",
        "             open(os.path.join(output_dir, filename), 'w') as f_out:\n",
        "            for line in f_in:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    old_class = int(parts[0])\n",
        "                    new_class = class_mapping.get(old_class, old_class)\n",
        "                    parts[0] = str(new_class)\n",
        "                    f_out.write(' '.join(parts) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e7945d",
      "metadata": {
        "id": "a0e7945d"
      },
      "source": [
        "## Moving the images and labels to the desired location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162e8fc8",
      "metadata": {
        "id": "162e8fc8"
      },
      "outputs": [],
      "source": [
        "source = \"Singapore maritime.v5i.yolov8/train/images\"\n",
        "source_1 = \"Singapore maritime.v5i.yolov8/valid/images\"\n",
        "source_2 = \"Singapore maritime.v5i.yolov8/test/images\"\n",
        "destination = \"merged_dataset/images\"\n",
        "\n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        "allfiles_1 = os.listdir(source_1)\n",
        "allfiles_2 = os.listdir(source_2)\n",
        "\n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_1:\n",
        "    src_path = os.path.join(source_1, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_2:\n",
        "    src_path = os.path.join(source_2, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c465ec0",
      "metadata": {
        "id": "4c465ec0"
      },
      "outputs": [],
      "source": [
        "source = \"Singapore maritime.v5i.yolov8/train/labels_new\"\n",
        "source_1 = \"Singapore maritime.v5i.yolov8/valid/labels_new\"\n",
        "source_2 = \"Singapore maritime.v5i.yolov8/test/labels_new\"\n",
        "destination = \"merged_dataset/labels\"\n",
        "\n",
        "# gather all files\n",
        "allfiles = os.listdir(source)\n",
        "allfiles_1 = os.listdir(source_1)\n",
        "allfiles_2 = os.listdir(source_2)\n",
        "\n",
        "# iterate on all files to move them to destination folder\n",
        "for f in allfiles:\n",
        "    src_path = os.path.join(source, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_1:\n",
        "    src_path = os.path.join(source_1, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)\n",
        "\n",
        "for f in allfiles_2:\n",
        "    src_path = os.path.join(source_2, f)\n",
        "    dst_path = os.path.join(destination, f)\n",
        "    os.rename(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0387cc5",
      "metadata": {
        "id": "e0387cc5"
      },
      "source": [
        "# 2. Data exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257f5303",
      "metadata": {
        "id": "257f5303"
      },
      "source": [
        "## Building up the dataframe w/ current files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47da2922",
      "metadata": {
        "id": "47da2922"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Directory containing label .txt files\n",
        "labels_dir = 'merged_dataset/labels'\n",
        "files = sorted(glob.glob(os.path.join(labels_dir, '*.txt')))\n",
        "\n",
        "rows = []\n",
        "if not files:\n",
        "    # No label files found: create an empty dataframe with expected columns\n",
        "    print('No label files found in', labels_dir)\n",
        "    labels_df = pd.DataFrame(columns=['label_file', 'image_file', 'class', 'x', 'y', 'w', 'h'])\n",
        "else:\n",
        "    for fp in files:\n",
        "        basename = os.path.basename(fp)\n",
        "        image_name = os.path.splitext(basename)[0] + '.jpg'\n",
        "        # read non-empty lines\n",
        "        with open(fp, 'r', encoding='utf-8') as f:\n",
        "            lines = [ln.strip() for ln in f.readlines() if ln.strip() != '']\n",
        "        if not lines:\n",
        "            # file had no labels; create one row with NaNs for class and coords\n",
        "            rows.append({\n",
        "                'label_file': basename,\n",
        "                'image_file': image_name,\n",
        "                'class': pd.NA,\n",
        "                'x': pd.NA,\n",
        "                'y': pd.NA,\n",
        "                'w': pd.NA,\n",
        "                'h': pd.NA\n",
        "            })\n",
        "        else:\n",
        "            for ln in lines:\n",
        "                parts = ln.split()\n",
        "                # YOLO format: class x_center y_center width height\n",
        "                try:\n",
        "                    cls = int(parts[0]) if len(parts) >= 1 else pd.NA\n",
        "                except ValueError:\n",
        "                    cls = pd.NA\n",
        "                coords = [pd.NA, pd.NA, pd.NA, pd.NA]\n",
        "                if len(parts) >= 5:\n",
        "                    try:\n",
        "                        coords = [float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])]\n",
        "                    except ValueError:\n",
        "                        coords = [pd.NA, pd.NA, pd.NA, pd.NA]\n",
        "                rows.append({\n",
        "                    'label_file': basename,\n",
        "                    'image_file': image_name,\n",
        "                    'class': cls,\n",
        "                    'x': coords[0],\n",
        "                    'y': coords[1],\n",
        "                    'w': coords[2],\n",
        "                    'h': coords[3],\n",
        "                })\n",
        "    # build dataframe from parsed rows\n",
        "    labels_df = pd.DataFrame(rows)\n",
        "\n",
        "# compute summary stats\n",
        "total_files = len(files)\n",
        "total_boxes = int(labels_df['class'].notna().sum()) if not labels_df.empty else 0\n",
        "empty_label_files = int(labels_df.loc[labels_df['class'].isna(), 'label_file'].nunique()) if not labels_df.empty else 0\n",
        "print(f'Total label files scanned: {total_files}')\n",
        "print(f'Total bounding boxes (rows): {total_boxes}')\n",
        "print(f'Empty label files: {empty_label_files}')\n",
        "\n",
        "# show a sample preview\n",
        "labels_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76797245",
      "metadata": {
        "id": "76797245"
      },
      "source": [
        "## Summing up and plotting the class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affbc8a9",
      "metadata": {
        "id": "affbc8a9"
      },
      "outputs": [],
      "source": [
        "# Try to load class names from merged_dataset/data.yaml\n",
        "class_names = {}\n",
        "data_yaml_path = 'merged_dataset/data.yaml'\n",
        "if os.path.exists(data_yaml_path):\n",
        "    try:\n",
        "        import yaml\n",
        "        with open(data_yaml_path, 'r', encoding='utf-8') as f:\n",
        "            data = yaml.safe_load(f)\n",
        "        names = data.get('names') if isinstance(data, dict) else None\n",
        "        if isinstance(names, dict):\n",
        "            # keys may be strings; convert to ints\n",
        "            class_names = {int(k): v for k, v in names.items()}\n",
        "        elif isinstance(names, list):\n",
        "            class_names = {i: n for i, n in enumerate(names)}\n",
        "    except Exception:\n",
        "        # fallback: simple parse for a YAML 'names' block\n",
        "        try:\n",
        "            with open(data_yaml_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "            names_list = []\n",
        "            in_names = False\n",
        "            for ln in lines:\n",
        "                s = ln.strip()\n",
        "                if s.startswith('names:'):\n",
        "                    # might be inline list or start of block\n",
        "                    rest = s.split('names:', 1)[1].strip()\n",
        "                    if rest.startswith('['):\n",
        "                        # literal list, try eval safely\n",
        "                        import ast\n",
        "                        try:\n",
        "                            names_list = ast.literal_eval(rest)\n",
        "                        except Exception:\n",
        "                            names_list = []\n",
        "                        break\n",
        "                    else:\n",
        "                        in_names = True\n",
        "                        continue\n",
        "                if in_names:\n",
        "                    if s.startswith('-'):\n",
        "                        names_list.append(s.lstrip('-').strip().strip('\"'))\n",
        "                    else:\n",
        "                        break\n",
        "            class_names = {i: n for i, n in enumerate(names_list)}\n",
        "        except Exception:\n",
        "            class_names = {}\n",
        "else:\n",
        "    print(f'No data.yaml at {data_yaml_path}; falling back to numeric class IDs')\n",
        "\n",
        "# If labels_df is empty or has no class entries, show message\n",
        "if 'labels_df' not in globals() or labels_df.empty or labels_df['class'].dropna().empty:\n",
        "    print('No labeled bounding boxes to plot.')\n",
        "else:\n",
        "    counts = labels_df['class'].dropna().astype(int).value_counts().sort_index()\n",
        "    idx = list(counts.index)\n",
        "    vals = counts.values\n",
        "    x_labels = [class_names.get(i, str(i)) for i in idx]\n",
        "    plt.figure(figsize=(12,6))\n",
        "    bars = plt.bar(x_labels, vals, color='tab:blue')\n",
        "    plt.title('Class Distribution')\n",
        "    plt.ylabel('Number of bounding boxes')\n",
        "    plt.xlabel('Class')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "    # annotate counts on bars\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        plt.annotate(f'{int(h)}', xy=(bar.get_x() + bar.get_width() / 2, h), xytext=(0, 3), textcoords='offset points', ha='center', va='bottom', fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1765b805",
      "metadata": {
        "id": "1765b805"
      },
      "source": [
        "## Creating video with ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d788cf1",
      "metadata": {
        "id": "2d788cf1"
      },
      "outputs": [],
      "source": [
        "# Paths - adjust these to your setup\n",
        "images_dir = \"merged_dataset/images\"\n",
        "labels_dir = \"merged_dataset/labels\"\n",
        "output_video = \"ground_truth_video_singapore_maritime.mp4\"\n",
        "\n",
        "# Class names dictionary (adjust based on your dataset)\n",
        "class_names = {\n",
        "    0: \"bulk cargo carrier\",\n",
        "    1: \"container ship\",\n",
        "    2: \"fishing boat\",\n",
        "    3: \"general cargo ship\",\n",
        "    4: \"ore carrier\",\n",
        "    5: \"passenger ship\",\n",
        "    6: \"Boat\",\n",
        "    7: \"Buoy\",\n",
        "    8: \"Ferry\",\n",
        "    9: \"Flying bird-plane\",\n",
        "    10: \"Kayak\",\n",
        "    11: \"Other\",\n",
        "    12: \"Sail boat\",\n",
        "    13: \"Speed boat\",\n",
        "    14: \"Vessel-ship\",\n",
        "}\n",
        "\n",
        "# Filter only Singapore Maritime dataset images (they start with 'MVI')\n",
        "image_files = sorted(glob.glob(os.path.join(images_dir, \"MVI*.jpg\")))\n",
        "# Try other extensions if needed\n",
        "if not image_files:\n",
        "    image_files = sorted(glob.glob(os.path.join(images_dir, \"MVI*.png\")))\n",
        "\n",
        "# Check if we found any images\n",
        "if not image_files:\n",
        "    print(\"No Singapore Maritime dataset images found!\")\n",
        "else:\n",
        "    # Read first image to get dimensions\n",
        "    first_img = cv2.imread(image_files[0])\n",
        "    height, width = first_img.shape[:2]\n",
        "\n",
        "    # Define the output video writer using mp4v codec, 30fps\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, 30.0, (width, height))\n",
        "\n",
        "    # Process each image\n",
        "    print(f\"Processing {len(image_files)} images...\")\n",
        "\n",
        "    for idx, img_path in enumerate(image_files):\n",
        "        # Print progress message\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            print(f\"Processed {idx + 1}/{len(image_files)} images\")\n",
        "\n",
        "        # Read the image\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Skip if image couldn't be loaded\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not load {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Get corresponding label file\n",
        "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        label_path = os.path.join(labels_dir, f\"{img_name}.txt\")\n",
        "\n",
        "        # Get all bounding boxes for this image\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "\n",
        "                    # Skip if no class information\n",
        "                    if len(parts) < 5:\n",
        "                        continue\n",
        "\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center, box_width, box_height = map(\n",
        "                        float, parts[1:5]\n",
        "                    )\n",
        "\n",
        "                    # Convert YOLO format to pixel coordinates\n",
        "                    x_center_px = int(x_center * width)\n",
        "                    y_center_px = int(y_center * height)\n",
        "                    box_width_px = int(box_width * width)\n",
        "                    box_height_px = int(box_height * height)\n",
        "\n",
        "                    # Calculate the corner points from center, width, height\n",
        "                    x1 = int(x_center_px - box_width_px / 2)\n",
        "                    y1 = int(y_center_px - box_height_px / 2)\n",
        "                    x2 = int(x_center_px + box_width_px / 2)\n",
        "                    y2 = int(y_center_px + box_height_px / 2)\n",
        "\n",
        "                    # Draw rectangle (green color)\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                    # Get class name if available from the class_names dict\n",
        "                    class_label = class_names.get(class_id, f\"Class_{class_id}\")\n",
        "\n",
        "                    # Put class name text above the box\n",
        "                    cv2.putText(\n",
        "                        img, class_label, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2\n",
        "                    )\n",
        "\n",
        "        # Write frame to video\n",
        "        out.write(img)\n",
        "\n",
        "    # Release the video writer\n",
        "    out.release()\n",
        "    #print(f\"Video saved to {output_video}\")\n",
        "    #print(f\"Total frames: {len(image_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3d95d9",
      "metadata": {
        "id": "3c3d95d9"
      },
      "outputs": [],
      "source": [
        "for label, label_name in class_names.items():\n",
        "    print(f\"Class ID: {label}, Class Name: {label_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb5e5f8",
      "metadata": {
        "id": "7fb5e5f8"
      },
      "outputs": [],
      "source": [
        "labels_df = labels_df.loc[(labels_df['class'] != 7) & (labels_df['class'] != 9) & (labels_df['class'] != 11) & (labels_df['class'].notna())]\n",
        "labels_df['class'].replace({4:0, 5:0, 1:0, 0:0, 3:0, 2:0, 14:0, 6:1, 13:1, 8:1, 12:1, 10:1}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ffca0a",
      "metadata": {
        "id": "16ffca0a"
      },
      "outputs": [],
      "source": [
        "labels_df = labels_df.loc[(labels_df['class'] != 7) & (labels_df['class'] != 9) & (labels_df['class'] != 11) & (labels_df['class'].notna())]\n",
        "labels_df['class'].replace({1:0}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0e7a8b",
      "metadata": {
        "id": "bf0e7a8b"
      },
      "source": [
        "# Image preparation for the training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3981a808",
      "metadata": {
        "id": "3981a808"
      },
      "source": [
        "## Dividing data (SMD + SeaShip) into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53837bc",
      "metadata": {
        "id": "a53837bc"
      },
      "outputs": [],
      "source": [
        "train_set = labels_df.sample(frac=0.7, random_state=42)\n",
        "\n",
        "# Dropping all those indexes from the dataframe that exists in the train_set\n",
        "test_set = labels_df.drop(train_set.index)\n",
        "train_set.shape, test_set.shape\n",
        "\n",
        "valid_set = test_set.sample(frac=0.33, random_state=42)\n",
        "test_set = test_set.drop(valid_set.index)\n",
        "train_set.shape, test_set.shape, valid_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fcae1d1",
      "metadata": {
        "id": "7fcae1d1"
      },
      "outputs": [],
      "source": [
        "valid_set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6be9475",
      "metadata": {
        "id": "f6be9475"
      },
      "source": [
        "## Creating folders for train, test, valid splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76c3106",
      "metadata": {
        "id": "d76c3106"
      },
      "outputs": [],
      "source": [
        "for file in train_set['image_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/images', file)\n",
        "    dst_path = os.path.join('final_dataset/train/images', file)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "for file_label in train_set['label_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
        "    dst_path = os.path.join('final_dataset/train/labels', file_label)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "for file in valid_set['image_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/images', file)\n",
        "    dst_path = os.path.join('final_dataset/valid/images', file)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "for file_label in valid_set['label_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
        "    dst_path = os.path.join('final_dataset/valid/labels', file_label)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "for file in test_set['image_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/images', file)\n",
        "    dst_path = os.path.join('final_dataset/test/images', file)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "for file_label in test_set['label_file'].unique():\n",
        "    src_path = os.path.join('merged_dataset/labels', file_label)\n",
        "    dst_path = os.path.join('final_dataset/test/labels', file_label)\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    shutil.copy2(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707f88f2",
      "metadata": {
        "id": "707f88f2"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "t = gc.get_threshold()\n",
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bcb1443",
      "metadata": {
        "id": "2bcb1443"
      },
      "source": [
        "## Training the yolo model w/out augmentation (Seaships + SMD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b024fa55",
      "metadata": {
        "id": "b024fa55",
        "outputId": "3aec3f28-46d2-4e2e-8f91-9fb834ba0f5e"
      },
      "outputs": [],
      "source": [
        "# Load a COCO-pretrained YOLOv8s model\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n",
        "\n",
        "# Train the model on the COCO8 example dataset for 100 epochs\n",
        "results = model.train(data=\"final_dataset/data.yaml\", epochs=10, imgsz=640)\n",
        "results\n",
        "\n",
        "###\n",
        "### DID NOT WORK WELL ENOUGH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3973ea",
      "metadata": {
        "id": "6e3973ea"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e874ed",
      "metadata": {
        "id": "f8e874ed"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa1ea04",
      "metadata": {
        "id": "eaa1ea04",
        "outputId": "1eef223f-0b7a-455a-bf29-4972541bf9df"
      },
      "outputs": [],
      "source": [
        "# Model Loading\n",
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train\\weights\\best.pt\")\n",
        "\n",
        "# Training with aggressive augmentation for difficult lighting conditions\n",
        "results = model.train(\n",
        "    data=\"fine_set_last/data.yaml\",\n",
        "    epochs=15,          # Short fine-tuning phase\n",
        "    imgsz=1280,         # High resolution (effective for small details on the bridge)\n",
        "\n",
        "    # --- PHOTOMETRIC AUGMENTATIONS (Key for sunlight handling) ---\n",
        "    hsv_h=0.015,        # Hue adjustment (subtle)\n",
        "    hsv_s=0.7,          # Saturation adjustment (aggressive - sunlight alters colors)\n",
        "    hsv_v=0.6,          # Brightness adjustment (aggressive - simulating shadows and overexposure)\n",
        "\n",
        "    # --- GEOMETRIC AUGMENTATIONS ---\n",
        "    degrees=5.0,        # Slight rotation (simulates camera sway in the wind)\n",
        "    translate=0.1,      # Image translation/shift\n",
        "    scale=0.5,          # Scaling (important for varying object distances)\n",
        "    fliplr=0.5,         # Horizontal flip (almost always beneficial)\n",
        "\n",
        "    # --- SPECIAL AUGMENTATIONS ---\n",
        "    mosaic=1.0,         # Enabled (improves context learning)\n",
        "    mixup=0.1,          # Image blending (optional, helps with dense crowds/details)\n",
        "    batch=-1,           # Auto-batch size (uses maximum available GPU memory)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6dd362",
      "metadata": {},
      "source": [
        "## All options with the fine tunings below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2465c467",
      "metadata": {},
      "source": [
        "### Main model development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a4f790",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a COCO-pretrained YOLOv8s model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n",
        "\n",
        "# Train the model on the COCO8 example dataset for 100 epochs\n",
        "results = model.train(data=r\"final_dataset\\data.yaml\", epochs=10, imgsz=640)\n",
        "results\n",
        "\n",
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06cf1d2",
      "metadata": {},
      "source": [
        "### Mixed-dataset based fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc85acf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Loading\n",
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train4\\weights\\best.pt\")\n",
        "\n",
        "# Training with aggressive augmentation for difficult lighting conditions\n",
        "results = model.train(\n",
        "    data=\"fine_set_last/data.yaml\",\n",
        "    epochs=15,          # Short fine-tuning phase\n",
        "    imgsz=1280,         # High resolution (effective for small details on the bridge)\n",
        "    batch=-1,           # Auto-batch size (uses maximum available GPU memory)\n",
        "\n",
        "    # --- PHOTOMETRIC AUGMENTATIONS (Critical for harsh sunlight) ---\n",
        "    hsv_h=0.015,        # Hue adjustment (subtle)\n",
        "    hsv_s=0.7,          # Saturation adjustment (aggressive - sunlight alters color perception)\n",
        "    hsv_v=0.6,          # Brightness adjustment (aggressive - simulates shadows and overexposure)\n",
        "\n",
        "    # --- GEOMETRIC AUGMENTATIONS ---\n",
        "    degrees=5.0,        # Slight rotation (simulates camera sway in the wind)\n",
        "    translate=0.1,      # Image translation/shifting\n",
        "    scale=0.5,          # Scaling (important when objects vary in distance)\n",
        "    fliplr=0.5,         # Horizontal flip (almost always improves robustness)\n",
        "\n",
        "    # --- SPECIAL AUGMENTATIONS ---\n",
        "    mosaic=1.0,         # Enabled (helps model learn objects in different contexts)\n",
        "    mixup=0.1,          # Image blending (optional, helps with occlusion/dense details)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d6db19",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c59729",
      "metadata": {},
      "source": [
        "#### Camera_1 validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5ccbec",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train4\\weights\\best.pt\")\n",
        "\n",
        "results = model.val(data=r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\camera_1\\data.yaml\", imgsz=1240)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fbb4ee",
      "metadata": {},
      "source": [
        "#### Camera_2 validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9530428a",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train4\\weights\\best.pt\")\n",
        "\n",
        "results = model.val(data=r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\camera_2\\data.yaml\", imgsz=1240)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a63a5a",
      "metadata": {},
      "source": [
        "### SeaShip pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d8ef7ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a COCO-pretrained YOLOv8s model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n",
        "\n",
        "# Train the model on the COCO8 example dataset for 100 epochs\n",
        "results = model.train(data=r\"seaships\\data.yaml\", epochs=10, imgsz=640)\n",
        "results\n",
        "\n",
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4949f45",
      "metadata": {},
      "source": [
        "### Sea-ship model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52b90f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Loading\n",
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train3\\weights\\best.pt\")\n",
        "\n",
        "# Training with aggressive augmentation for difficult lighting conditions\n",
        "results = model.train(\n",
        "    data=\"fine_set_last/data.yaml\",\n",
        "    epochs=15,          # Short fine-tuning phase\n",
        "    imgsz=1280,         # High resolution (effective for small details on the bridge)\n",
        "\n",
        "    # --- PHOTOMETRIC AUGMENTATIONS (Critical for handling sunlight) ---\n",
        "    hsv_h=0.015,        # Hue adjustment (subtle)\n",
        "    hsv_s=0.7,          # Saturation adjustment (aggressive - sunlight alters color perception)\n",
        "    hsv_v=0.6,          # Brightness adjustment (aggressive - simulates shadows and overexposure)\n",
        "\n",
        "    # --- GEOMETRIC AUGMENTATIONS ---\n",
        "    degrees=5.0,        # Slight rotation (simulates camera sway in the wind)\n",
        "    translate=0.1,      # Image translation/shifting\n",
        "    scale=0.5,          # Scaling (important when objects vary in distance/depth)\n",
        "    fliplr=0.5,         # Horizontal flip (almost always improves robustness)\n",
        "\n",
        "    # --- SPECIAL AUGMENTATIONS ---\n",
        "    mosaic=1.0,         # Enabled (improves context learning)\n",
        "    mixup=0.1,          # Image blending/overlay (helps with dense crowds or overlapping details)\n",
        "    batch=-1,           # Auto-batch size (optimizes based on available GPU memory)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218f5ccc",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afeb6818",
      "metadata": {},
      "source": [
        "### Singapore Maritime Dataset pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946a9aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a COCO-pretrained YOLOv8s model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Display model information (optional)\n",
        "model.info()\n",
        "\n",
        "# Train the model on the COCO8 example dataset for 100 epochs\n",
        "results = model.train(data=r\"Singapore maritime.v5i.yolov8\\data.yaml\", epochs=10, imgsz=640)\n",
        "results\n",
        "\n",
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e9187cc",
      "metadata": {},
      "source": [
        "### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a673d65",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train\\weights\\best.pt\")\n",
        "\n",
        "# Training with aggressive augmentation for difficult lighting conditions\n",
        "results = model.train(\n",
        "    data=\"fine_set_last/data.yaml\",\n",
        "    epochs=15,          # Short fine-tuning\n",
        "    imgsz=1280,         # High resolution (beneficial for small details on the bridge)\n",
        "\n",
        "    # --- Photometric Augmentations (Critical for sunlight/shadows) ---\n",
        "    hsv_h=0.015,        # Hue adjustment (slight)\n",
        "    hsv_s=0.7,          # Saturation adjustment (aggressive - sun changes colors)\n",
        "    hsv_v=0.6,          # Value/Brightness adjustment (aggressive - simulates shadows and overexposure)\n",
        "\n",
        "    # --- Geometric Augmentations ---\n",
        "    degrees=5.0,        # Slight rotation (simulating camera sway due to wind)\n",
        "    translate=0.1,      # Image translation\n",
        "    scale=0.5,          # Scaling (important for varying object distances)\n",
        "    fliplr=0.5,         # Horizontal flip (almost always useful)\n",
        "\n",
        "    # --- Special Augmentations ---\n",
        "    mosaic=1.0,         # Mosaic augmentation (helps learn context)\n",
        "    mixup=0.1,          # MixUp (image blending, optional)\n",
        "    batch=-1,           # Auto-batch size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "face8da0",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = model.val(split='test')\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91bb80e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fa2755",
      "metadata": {
        "id": "f7fa2755",
        "outputId": "e563a471-ad33-4782-d995-1299c614fdba"
      },
      "outputs": [],
      "source": [
        "# ================= CONFIGURATION =================\n",
        "# Update these paths to match your actual local setup\n",
        "SOURCE_ROOT = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\")\n",
        "OUTPUT_ROOT = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Processed_Dataset\")\n",
        "\n",
        "CAMERAS = [\"camera_1\", \"camera_2\"]\n",
        "SUBSETS = [\"train\", \"test\", \"valid\"]\n",
        "\n",
        "# Regex to find date/time in filename: frame_20251213_135019_...\n",
        "FILENAME_PATTERN = re.compile(r\"frame_(\\d{8})_(\\d{6})_\")\n",
        "\n",
        "def extract_metadata(filename):\n",
        "    \"\"\"Parses filename for datetime and converts to timestamp.\"\"\"\n",
        "    match = FILENAME_PATTERN.search(filename)\n",
        "    if match:\n",
        "        date_str, time_str = match.groups()\n",
        "        dt_obj = datetime.strptime(f\"{date_str}{time_str}\", \"%Y%m%d%H%M%S\")\n",
        "        return dt_obj, dt_obj.timestamp()\n",
        "    return None, None\n",
        "\n",
        "def count_objects(label_path):\n",
        "    \"\"\"Counts lines in a YOLO txt file (1 line = 1 object).\"\"\"\n",
        "    if not os.path.exists(label_path):\n",
        "        return 0\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "        return len(lines)\n",
        "\n",
        "def get_unique_filename(directory, filename, extension):\n",
        "    \"\"\"\n",
        "    Checks if a file exists. If so, adds _1, _2, etc.\n",
        "    Returns the full path including the unique filename.\n",
        "    \"\"\"\n",
        "    base_name = filename\n",
        "    counter = 0\n",
        "    while True:\n",
        "        if counter == 0:\n",
        "            candidate = f\"{base_name}{extension}\"\n",
        "        else:\n",
        "            candidate = f\"{base_name}_{counter}{extension}\"\n",
        "\n",
        "        full_path = directory / candidate\n",
        "        if not full_path.exists():\n",
        "            return full_path\n",
        "        counter += 1\n",
        "\n",
        "def main():\n",
        "    data_records = []\n",
        "\n",
        "    print(f\"--- Starting Processing from {SOURCE_ROOT} ---\")\n",
        "\n",
        "    for camera in CAMERAS:\n",
        "        for subset in SUBSETS:\n",
        "            img_dir = SOURCE_ROOT / camera / subset / \"images\"\n",
        "            lbl_dir = SOURCE_ROOT / camera / subset / \"labels\"\n",
        "\n",
        "            if not img_dir.exists():\n",
        "                continue\n",
        "\n",
        "            image_files = list(img_dir.glob(\"*.jpg\"))\n",
        "\n",
        "            for img_path in image_files:\n",
        "                # 1. Extract Info\n",
        "                dt_obj, timestamp = extract_metadata(img_path.name)\n",
        "\n",
        "                if not dt_obj:\n",
        "                    print(f\"Skipping {img_path.name}: Date parsing failed\")\n",
        "                    continue\n",
        "\n",
        "                date_folder_str = dt_obj.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "                # 2. Find corresponding label\n",
        "                label_name = img_path.stem + \".txt\"\n",
        "                label_path = lbl_dir / label_name\n",
        "\n",
        "                ship_count = count_objects(label_path)\n",
        "\n",
        "                # 3. Store Data\n",
        "                data_records.append({\n",
        "                    \"Camera\": camera,\n",
        "                    \"Subset\": subset,\n",
        "                    \"Original_Filename\": img_path.name,\n",
        "                    \"Unix_Timestamp\": int(timestamp), # Convert float to int\n",
        "                    \"Date_Str\": date_folder_str,\n",
        "                    \"Hour\": dt_obj.hour,\n",
        "                    \"Ship_Count\": ship_count,\n",
        "                    \"Src_Img\": img_path,\n",
        "                    \"Src_Lbl\": label_path\n",
        "                })\n",
        "\n",
        "    df = pd.DataFrame(data_records)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"No images found to process.\")\n",
        "        return\n",
        "\n",
        "    # ================= TASK 1: RESTRUCTURE & RENAME =================\n",
        "    print(\"\\n--- Restructuring and Renaming Files ---\")\n",
        "\n",
        "    files_moved = 0\n",
        "    for _, row in df.iterrows():\n",
        "        # Define target folders: output/camera/date/images/\n",
        "        target_base = OUTPUT_ROOT / row['Camera'] / row['Date_Str']\n",
        "        target_img_dir = target_base / \"images\"\n",
        "        target_lbl_dir = target_base / \"labels\"\n",
        "\n",
        "        # Create dirs\n",
        "        target_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "        target_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Generate UNIX Filename\n",
        "        unix_name = str(row['Unix_Timestamp'])\n",
        "\n",
        "        # Check for collisions and get unique path\n",
        "        dest_img_path = get_unique_filename(target_img_dir, unix_name, \".jpg\")\n",
        "\n",
        "        # Determine the final name used (might have _1 appended)\n",
        "        final_stem = dest_img_path.stem\n",
        "        dest_lbl_path = target_lbl_dir / f\"{final_stem}.txt\"\n",
        "\n",
        "        # Copy Image\n",
        "        shutil.copy2(row['Src_Img'], dest_img_path)\n",
        "\n",
        "        # Copy Label (if exists)\n",
        "        if os.path.exists(row['Src_Lbl']):\n",
        "            shutil.copy2(row['Src_Lbl'], dest_lbl_path)\n",
        "\n",
        "        files_moved += 1\n",
        "\n",
        "    print(f\"Successfully processed and renamed {files_moved} files to {OUTPUT_ROOT}\")\n",
        "\n",
        "    # ================= TASK 2: SUMMARY ((images, annotations, days, hours)) =================\n",
        "    print(\"\\n--- Detailed Summary ---\")\n",
        "    detailed_summary = df.groupby('Camera').agg(\n",
        "        Images=('Original_Filename', 'count'),\n",
        "        Annotations=('Ship_Count', 'sum'),\n",
        "        Unique_Days=('Date_Str', 'nunique'),\n",
        "        Unique_Hours=('Hour', 'nunique')\n",
        "    ).reset_index()\n",
        "\n",
        "    detailed_summary.columns = ['Camera', 'Images', 'Annotations', 'Days', 'Hours']\n",
        "    print(detailed_summary.to_string(index=False))\n",
        "\n",
        "    # ================= TASK 3: DATASET REQ (Assorted Date) =================\n",
        "    print(\"\\n--- Final Dataset Request ---\")\n",
        "\n",
        "    final_report = df.groupby('Camera').agg(\n",
        "        Images=('Original_Filename', 'count'),\n",
        "        Ships=('Ship_Count', 'sum'),\n",
        "        Unique_Dates=('Date_Str', 'unique')\n",
        "    ).reset_index()\n",
        "\n",
        "    def format_date_column(dates):\n",
        "        if len(dates) > 1:\n",
        "            return \"assorted\"\n",
        "        elif len(dates) == 1:\n",
        "            return dates[0]\n",
        "        else:\n",
        "            return \"N/A\"\n",
        "\n",
        "    final_report['Date'] = final_report['Unique_Dates'].apply(format_date_column)\n",
        "    final_output = final_report[['Camera', 'Images', 'Ships', 'Date']]\n",
        "\n",
        "    print(final_output.to_string(index=False))\n",
        "\n",
        "    # Save CSV\n",
        "    final_output.to_csv(OUTPUT_ROOT / \"dataset_summary.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1d9e28",
      "metadata": {
        "id": "5c1d9e28",
        "outputId": "23fb6637-613f-46d3-a6be-35295ab19a93"
      },
      "outputs": [],
      "source": [
        "SOURCE_ROOT = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Processed_Dataset\")\n",
        "CAMERAS = [\"camera_1\", \"camera_2\"]\n",
        "\n",
        "def get_timestamps(camera_name):\n",
        "    print(f\"Fetching data for {camera_name}...\")\n",
        "    path = SOURCE_ROOT / camera_name\n",
        "    timestamps = []\n",
        "    \n",
        "    # Extract filename (without .jpg) and convert to int\n",
        "    # Handles names like: 123456.jpg and 123456_1.jpg\n",
        "    for f in path.rglob(\"*.jpg\"):\n",
        "        stem = f.stem.split('_')[0] # Removes potential _1 suffix\n",
        "        if stem.isdigit():\n",
        "            timestamps.append(int(stem))\n",
        "    return sorted(list(set(timestamps))) # Sort for easier comparison\n",
        "\n",
        "def main():\n",
        "    # 1. Get sorted timestamp lists\n",
        "    t1 = get_timestamps(CAMERAS[0])\n",
        "    t2 = get_timestamps(CAMERAS[1])\n",
        "\n",
        "    if not t1 or not t2:\n",
        "        print(\"No data found in folders!\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nFound: Cam1={len(t1)}, Cam2={len(t2)}\")\n",
        "\n",
        "    # 2. Find nearest neighbors\n",
        "    # Logic: For every timestamp T in Cam1, find the nearest T in Cam2\n",
        "\n",
        "    deltas = []\n",
        "    matched_counts = {\n",
        "        \"exact\": 0,      # 0s difference\n",
        "        \"close_1s\": 0,   # <= 1s difference\n",
        "        \"close_3s\": 0,   # <= 3s difference\n",
        "        \"far\": 0         # > 3s difference\n",
        "    }\n",
        "\n",
        "    # Convert to array for performance\n",
        "    arr2 = np.array(t2)\n",
        "\n",
        "    print(\"Analyzing time differences...\")\n",
        "    for val1 in t1:\n",
        "        # Find index where val1 should be inserted in sorted arr2 to maintain order\n",
        "        idx = np.searchsorted(arr2, val1, side=\"left\")\n",
        "\n",
        "        # Check neighbors (left and right) to find the absolute nearest value\n",
        "        candidates = []\n",
        "        if idx < len(arr2): candidates.append(arr2[idx])\n",
        "        if idx > 0: candidates.append(arr2[idx-1])\n",
        "\n",
        "        if not candidates:\n",
        "            continue\n",
        "\n",
        "        # Choose the best candidate (smallest absolute difference)\n",
        "        closest_val2 = min(candidates, key=lambda x: abs(x - val1))\n",
        "        diff = closest_val2 - val1 # If negative, Cam2 timestamp is earlier\n",
        "        abs_diff = abs(diff)\n",
        "\n",
        "        deltas.append(diff)\n",
        "\n",
        "        if abs_diff == 0: matched_counts[\"exact\"] += 1\n",
        "        elif abs_diff <= 1: matched_counts[\"close_1s\"] += 1\n",
        "        elif abs_diff <= 3: matched_counts[\"close_3s\"] += 1\n",
        "        else: matched_counts[\"far\"] += 1\n",
        "\n",
        "    # 3. Generate Report\n",
        "    avg_offset = np.mean(deltas)\n",
        "    median_offset = np.median(deltas)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"TIME SHIFT DIAGNOSTICS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Mean offset (Cam2 - Cam1): {avg_offset:.2f} sec\")\n",
        "    print(f\"Median offset: {median_offset:.2f} sec\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Match distribution:\")\n",
        "    print(f\"Exact (0s):       {matched_counts['exact']}\")\n",
        "    print(f\"Very close (1s):  {matched_counts['close_1s']}\")\n",
        "    print(f\"Close (<=3s):     {matched_counts['close_3s']}\")\n",
        "    print(f\"Far (>3s):        {matched_counts['far']}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if abs(median_offset) > 3600:\n",
        "        print(\"Looks like a timezone error (difference > 1h).\")\n",
        "    elif abs(median_offset) > 10:\n",
        "        print(\"Camera clocks are desynchronized by a constant value.\")\n",
        "    elif matched_counts['close_1s'] > 100:\n",
        "        print(\"Cameras are synchronized, but have a small delay (<1s).\")\n",
        "        print(\"   You must accept matching with +/- 1s tolerance.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fdafdbc",
      "metadata": {
        "id": "8fdafdbc",
        "outputId": "484c8e3d-3771-4ea5-9c36-34983f1e4c64"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Processed_Dataset\")\n",
        "OUTPUT_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Szymon_dataset_and_plot\")\n",
        "\n",
        "def main():\n",
        "    print(f\"Analyzing dataset at {DATASET_DIR}\")\n",
        "\n",
        "    if not DATASET_DIR.exists():\n",
        "        print(\"Error: Dataset directory not found.\")\n",
        "        return\n",
        "\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    hours = []\n",
        "    total_images = 0\n",
        "\n",
        "    for img_path in DATASET_DIR.rglob(\"*.jpg\"):\n",
        "        total_images += 1\n",
        "        stem = img_path.stem.split('_')[0]\n",
        "\n",
        "        if stem.isdigit():\n",
        "            timestamp = int(stem)\n",
        "            dt = datetime.fromtimestamp(timestamp)\n",
        "            hours.append(dt.hour)\n",
        "\n",
        "    print(f\"Found {total_images} images.\")\n",
        "\n",
        "    if total_images == 0:\n",
        "        return\n",
        "\n",
        "    print(\"Generating Histogram...\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(hours, bins=range(25), color='#2c3e50', edgecolor='white', alpha=0.8, align='left')\n",
        "\n",
        "    plt.title(f\"Dataset Distribution by Hour of Day (n={total_images})\", fontsize=14)\n",
        "    plt.xlabel(\"Hour of Day (0-23)\", fontsize=12)\n",
        "    plt.ylabel(\"Number of Images\", fontsize=12)\n",
        "    plt.xticks(range(0, 24))\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plot_path = OUTPUT_DIR / \"dataset_hour_histogram.png\"\n",
        "    plt.savefig(plot_path, dpi=300)\n",
        "    print(f\"Histogram saved to: {plot_path}\")\n",
        "\n",
        "    print(\"\\nCreating ZIP archive...\")\n",
        "    zip_name = OUTPUT_DIR / \"final_dataset\"\n",
        "    shutil.make_archive(zip_name, 'zip', DATASET_DIR)\n",
        "\n",
        "    print(f\"SUCCESS: Dataset compressed to {zip_name}.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9632058f",
      "metadata": {
        "id": "9632058f",
        "outputId": "4c20b916-1256-47bc-f95c-974cfdea40bd"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Processed_Dataset\")\n",
        "OUTPUT_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Szymon_dataset_and_plot\")\n",
        "\n",
        "def main():\n",
        "    print(\"Generating Plot (8-17 range)...\")\n",
        "\n",
        "    if not OUTPUT_DIR.exists():\n",
        "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if not DATASET_DIR.exists():\n",
        "        print(\"Error: Dataset folder not found.\")\n",
        "        return\n",
        "\n",
        "    hours = []\n",
        "    total_images = 0\n",
        "\n",
        "    for img_path in DATASET_DIR.rglob(\"*.jpg\"):\n",
        "        total_images += 1\n",
        "        stem = img_path.stem.split('_')[0]\n",
        "        if stem.isdigit():\n",
        "            timestamp = int(stem)\n",
        "            dt = datetime.fromtimestamp(timestamp)\n",
        "            hours.append(dt.hour)\n",
        "\n",
        "    if total_images == 0:\n",
        "        print(\"No images found.\")\n",
        "        return\n",
        "\n",
        "    print(\"Drawing histogram...\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    bins = np.arange(0, 25) - 0.5\n",
        "\n",
        "    plt.hist(hours, bins=bins, color='#4c72b0', edgecolor='black', alpha=0.9, rwidth=0.8, zorder=3)\n",
        "\n",
        "    target_hours = range(8, 18)\n",
        "    hour_labels = [f\"{h:02d}:00\" for h in target_hours]\n",
        "\n",
        "    plt.xticks(ticks=target_hours, labels=hour_labels, rotation=45, ha='right', fontsize=11)\n",
        "    plt.xlim([7.5, 17.5])\n",
        "\n",
        "    plt.xlabel(\"Time of Day (Local Time)\", fontsize=12)\n",
        "    plt.ylabel(\"Image Count\", fontsize=12)\n",
        "\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.5, zorder=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plot_path = OUTPUT_DIR / \"dataset_hour_histogram_8_17.png\"\n",
        "    plt.savefig(plot_path, dpi=300)\n",
        "\n",
        "    print(f\"Done! Plot saved to:\\n{plot_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4c8d0b",
      "metadata": {
        "id": "9e4c8d0b",
        "outputId": "c63e3376-110c-477f-e27a-7f8ebf4d2466"
      },
      "outputs": [],
      "source": [
        "# Input: Where your current raw folders are (camera_1, camera_2)\n",
        "SOURCE_ROOT = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\")\n",
        "\n",
        "# Output: Where the new, organized dataset will be created\n",
        "OUTPUT_ROOT = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Processed_Dataset\")\n",
        "\n",
        "SUBSETS = [\"train\", \"test\", \"valid\"]\n",
        "\n",
        "# Mapping raw folder names to Article/Display names\n",
        "NAME_MAPPING = {\n",
        "    \"camera_1\": \"East pylon\",\n",
        "    \"camera_2\": \"Sprogoe\"\n",
        "}\n",
        "\n",
        "# Metadata descriptions\n",
        "FOOTPRINTS = {\n",
        "    \"East pylon\": \"Loc: East Bridge Pylon, View: High-angle Roadway & Cables, Dir: West (towards Sprogoe)\",\n",
        "    \"Sprogoe\":    \"Loc: Sprogoe/Coast, View: Bridge Profile (Side View), Dir: East/South-East\"\n",
        "}\n",
        "\n",
        "# Regex to find date/time in original filenames (e.g., frame_20231005_120000)\n",
        "FILENAME_PATTERN = re.compile(r\"frame_(\\d{8})_(\\d{6})_\")\n",
        "\n",
        "def get_unique_path(directory, filename, ext):\n",
        "    \"\"\"Ensures we don't overwrite files if timestamps are identical.\"\"\"\n",
        "    base = filename\n",
        "    counter = 0\n",
        "    while True:\n",
        "        suffix = f\"_{counter}\" if counter > 0 else \"\"\n",
        "        full_path = directory / f\"{base}{suffix}{ext}\"\n",
        "        if not full_path.exists():\n",
        "            return full_path\n",
        "\n",
        "def main():\n",
        "    metadata_records = []\n",
        "    print(f\"Generating dataset at: {OUTPUT_ROOT}\")\n",
        "\n",
        "    for source_folder_name, new_camera_name in NAME_MAPPING.items():\n",
        "        print(f\"Processing: '{source_folder_name}' -> '{new_camera_name}'\")\n",
        "\n",
        "        footprint = FOOTPRINTS.get(new_camera_name, \"Unknown View\")\n",
        "\n",
        "        for subset in SUBSETS:\n",
        "            img_src_dir = SOURCE_ROOT / source_folder_name / subset / \"images\"\n",
        "            lbl_src_dir = SOURCE_ROOT / source_folder_name / subset / \"labels\"\n",
        "\n",
        "            if not img_src_dir.exists():\n",
        "                print(f\"   Skipped (missing): {img_src_dir}\")\n",
        "                continue\n",
        "\n",
        "            for src_img in img_src_dir.rglob(\"*.jpg\"):\n",
        "                # Extract date from filename\n",
        "                match = FILENAME_PATTERN.search(src_img.name)\n",
        "                if not match:\n",
        "                    continue\n",
        "\n",
        "                d_str, t_str = match.groups()\n",
        "                dt = datetime.strptime(f\"{d_str}{t_str}\", \"%Y%m%d%H%M%S\")\n",
        "                timestamp = int(dt.timestamp())\n",
        "                date_str = dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "                # Define new path structure\n",
        "                target_dir = OUTPUT_ROOT / new_camera_name / date_str\n",
        "                (target_dir / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "                (target_dir / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                # Copy and Rename Image to Timestamp\n",
        "                dest_img = get_unique_path(target_dir / \"images\", str(timestamp), \".jpg\")\n",
        "                shutil.copy2(src_img, dest_img)\n",
        "                final_name = dest_img.name\n",
        "\n",
        "                # Process Label if it exists\n",
        "                src_lbl = lbl_src_dir / (src_img.stem + \".txt\")\n",
        "                ship_count = 0\n",
        "                if src_lbl.exists():\n",
        "                    dest_lbl = target_dir / \"labels\" / final_name.replace(\".jpg\", \".txt\")\n",
        "                    shutil.copy2(src_lbl, dest_lbl)\n",
        "                    \n",
        "                    with open(src_lbl, 'r') as f:\n",
        "                        ship_count = len([line for line in f if line.strip()])\n",
        "\n",
        "                # Collect Metadata\n",
        "                metadata_records.append({\n",
        "                    \"filename\": final_name,\n",
        "                    \"camera\": new_camera_name,\n",
        "                    \"split\": subset,\n",
        "                    \"date\": date_str,\n",
        "                    \"unix_timestamp\": timestamp,\n",
        "                    \"ship_count\": ship_count,\n",
        "                    \"view_footprint\": footprint\n",
        "                })\n",
        "\n",
        "    # Save Master CSV\n",
        "    if metadata_records:\n",
        "        df = pd.DataFrame(metadata_records)\n",
        "        df = df[[\"filename\", \"split\", \"camera\", \"date\", \"ship_count\", \"unix_timestamp\", \"view_footprint\"]]\n",
        "\n",
        "        meta_path = OUTPUT_ROOT / \"dataset_metadata.csv\"\n",
        "        df.to_csv(meta_path, index=False)\n",
        "        print(f\"\\nSUCCESS: Metadata saved to:\\n{meta_path}\")\n",
        "        print(\"\\nPreview:\")\n",
        "        print(df[['filename', 'camera', 'split', 'ship_count']].head().to_string(index=False))\n",
        "    else:\n",
        "        print(\"ERROR: No files found. Check NAME_MAPPING.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854c683a",
      "metadata": {
        "id": "854c683a",
        "outputId": "ef7f8e7c-8a80-4d14-d892-9c31b112fa58"
      },
      "outputs": [],
      "source": [
        "# ================= CONFIGURATION =================\n",
        "META_FILE = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\final_dataset\\dataset_metadata.csv\")\n",
        "OUTPUT_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\Szymon_dataset_and_plot\")\n",
        "\n",
        "# Days to filter (Format: 'MM-DD')\n",
        "TARGET_DAYS = ['01-08', '12-14']\n",
        "\n",
        "def main():\n",
        "    if not META_FILE.exists():\n",
        "        print(\"Error: Metadata file not found.\")\n",
        "        return\n",
        "    \n",
        "    if not OUTPUT_DIR.exists():\n",
        "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1. Load Data\n",
        "    df = pd.read_csv(META_FILE)\n",
        "    df['dt'] = pd.to_datetime(df['unix_timestamp'], unit='s')\n",
        "\n",
        "    # 2. Filter by Date (e.g., Jan 8 and Dec 14)\n",
        "    df['month_day'] = df['dt'].dt.strftime('%m-%d')\n",
        "    df_filtered = df[df['month_day'].isin(TARGET_DAYS)].copy()\n",
        "\n",
        "    if df_filtered.empty:\n",
        "        print(f\"WARNING: No images found for days: {TARGET_DAYS}\")\n",
        "        print(\"Available dates in file:\", df['date'].unique())\n",
        "        return\n",
        "    else:\n",
        "        print(f\"Found {len(df_filtered)} images for days: {TARGET_DAYS}\")\n",
        "\n",
        "    # 3. Prepare Plot Data\n",
        "    # X-Axis: Normalize everything to a single arbitrary date to compare times\n",
        "    df_filtered['time_of_day'] = df_filtered['dt'].apply(lambda x: x.replace(year=1900, month=1, day=1))\n",
        "\n",
        "    # Y-Axis: Sort chronologically so dates appear in order\n",
        "    df_filtered = df_filtered.sort_values(by=['date', 'camera'], ascending=[True, False])\n",
        "    df_filtered['y_label'] = df_filtered['date'] + \"  /  \" + df_filtered['camera']\n",
        "\n",
        "    # 4. Drawing\n",
        "    print(\"Generating plot...\")\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    colors = {\n",
        "        'East pylon': '#003366',  # Dark Blue\n",
        "        'Sprogoe':    '#66b3ff'   # Light Blue\n",
        "    }\n",
        "\n",
        "    y_labels = df_filtered['y_label'].unique()\n",
        "\n",
        "    for label in y_labels:\n",
        "        subset = df_filtered[df_filtered['y_label'] == label]\n",
        "        if subset.empty: continue\n",
        "\n",
        "        cam_name = subset['camera'].iloc[0]\n",
        "        col = colors.get(cam_name, 'gray')\n",
        "\n",
        "        # Strip Plot using scatter\n",
        "        plt.scatter(\n",
        "            subset['time_of_day'],\n",
        "            [label] * len(subset),\n",
        "            marker='|',\n",
        "            s=300,\n",
        "            color=col,\n",
        "            alpha=0.8,\n",
        "            linewidths=1.5\n",
        "        )\n",
        "\n",
        "    # 5. Formatting\n",
        "    ax = plt.gca()\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
        "\n",
        "    plt.xlabel(\"Time of Day (UTC / Local)\", fontsize=11)\n",
        "    \n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
        "    plt.grid(axis='y', linestyle='-', alpha=0.2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = OUTPUT_DIR / \"dataset_strip_plot.png\"\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"Plot saved to: {save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2235da9c",
      "metadata": {
        "id": "2235da9c"
      },
      "source": [
        "## Crosseval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90342dfb",
      "metadata": {
        "id": "90342dfb",
        "outputId": "aa3b79d6-3ba3-498a-e370-6d24e175e880"
      },
      "outputs": [],
      "source": [
        "# --- CONFIGURATION ---\n",
        "BASE_DIR = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\cross_mix\"\n",
        "CSV_PATH = os.path.join(BASE_DIR, \"dataset_metadata.csv\")\n",
        "\n",
        "# Key: Name in CSV 'camera' column\n",
        "# Value: Actual folder name on disk\n",
        "CAMERA_FOLDER_MAP = {\n",
        "    'East pylon': 'East Pylon',\n",
        "    'Sprogoe': 'Sprogoe'\n",
        "}\n",
        "\n",
        "def generate_configs_for_nested_structure():\n",
        "    if not os.path.exists(CSV_PATH):\n",
        "        raise FileNotFoundError(f\"dataset_metadata.csv not found at {CSV_PATH}\")\n",
        "\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    for csv_cam, folder_cam in CAMERA_FOLDER_MAP.items():\n",
        "        print(f\"Processing camera: {csv_cam} (Folder: {folder_cam})...\")\n",
        "\n",
        "        subset = df[df['camera'] == csv_cam]\n",
        "\n",
        "        if subset.empty:\n",
        "            print(f\"WARNING: No images found in CSV for camera '{csv_cam}'!\")\n",
        "            continue\n",
        "\n",
        "        file_paths = {'train': [], 'valid': [], 'test': []}\n",
        "\n",
        "        for index, row in subset.iterrows():\n",
        "            split = row['split']\n",
        "            date_folder = str(row['date'])\n",
        "            filename = row['filename']\n",
        "\n",
        "            # Path structure: cross_mix / Camera / Date / images / Filename\n",
        "            full_path = os.path.join(BASE_DIR, folder_cam, date_folder, 'images', filename)\n",
        "            \n",
        "            # Using absolute path for safety\n",
        "            file_paths[split].append(os.path.abspath(full_path))\n",
        "\n",
        "        txt_files_map = {}\n",
        "        for split_name, paths in file_paths.items():\n",
        "            if not paths:\n",
        "                continue\n",
        "\n",
        "            txt_filename = f\"{folder_cam.replace(' ', '_').lower()}_{split_name}.txt\"\n",
        "            with open(txt_filename, 'w') as f:\n",
        "                f.write('\\n'.join(paths))\n",
        "\n",
        "            txt_files_map[split_name] = os.path.abspath(txt_filename)\n",
        "            print(f\"   -> {split_name}: found {len(paths)} images -> saved to {txt_filename}\")\n",
        "\n",
        "        # YOLO expects 'val', CSV often has 'valid'\n",
        "        val_path = txt_files_map.get('valid') or txt_files_map.get('val')\n",
        "\n",
        "        yaml_content = f\"\"\"\n",
        "path: {BASE_DIR}\n",
        "train: {txt_files_map.get('train')}\n",
        "val: {val_path}\n",
        "test: {txt_files_map.get('test')}\n",
        "\n",
        "names:\n",
        "  0: ship\n",
        "\"\"\"\n",
        "        yaml_name = f\"{folder_cam.replace(' ', '_').lower()}.yaml\"\n",
        "        with open(yaml_name, 'w') as f:\n",
        "            f.write(yaml_content)\n",
        "\n",
        "        print(f\"   -> DONE: Config file created: {yaml_name}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_configs_for_nested_structure()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87bb9d32",
      "metadata": {},
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17eb680d",
      "metadata": {
        "id": "17eb680d",
        "outputId": "0f37b48e-3f46-4a1f-9487-4f05dfab7b6a"
      },
      "outputs": [],
      "source": [
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train4\\weights\\best.pt\")\n",
        "\n",
        "print(\"--- WYNIKI DLA EAST PYLON (Test Set) ---\")\n",
        "res_ep = model.val(data=\"east_pylon.yaml\", split='test')\n",
        "\n",
        "print(\"\\n--- WYNIKI DLA SPROGOE (Test Set) ---\")\n",
        "res_sp = model.val(data=\"sprogoe.yaml\", split='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d329e3",
      "metadata": {
        "id": "54d329e3"
      },
      "source": [
        "### Mixed crosscamera experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "484f2590",
      "metadata": {
        "id": "484f2590",
        "outputId": "f53c3da1-7898-4237-d2de-14f8e5981bb6"
      },
      "outputs": [],
      "source": [
        "# --- CONFIGURATION ---\n",
        "BASE_MODEL = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train26\\weights\\best.pt\"\n",
        "SPROGOE_DIR = Path(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\cross_mix\\East pylon\")\n",
        "\n",
        "WORK_DIR = Path(\"experiment_sprogoe_to_eastpylon\")\n",
        "IMG_SIZE = 1280\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 15\n",
        "FRACTIONS = [0.0, 0.10, 0.20, 0.30, 0.40, 0.50]\n",
        "\n",
        "AUG_PARAMS = {\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.6,\n",
        "    'degrees': 5.0,\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.5,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 1.0,\n",
        "    'mixup': 0.1,\n",
        "}\n",
        "\n",
        "def setup_directories():\n",
        "    if WORK_DIR.exists():\n",
        "        try:\n",
        "            shutil.rmtree(WORK_DIR)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: Could not remove {WORK_DIR}: {e}\")\n",
        "    WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def get_data_recursive(source_root):\n",
        "    pairs = []\n",
        "    print(f\"Scanning: {source_root}\")\n",
        "\n",
        "    all_images = (list(source_root.rglob(\"*.jpg\")) +\n",
        "                  list(source_root.rglob(\"*.png\")) +\n",
        "                  list(source_root.rglob(\"*.jpeg\")))\n",
        "\n",
        "    for img_path in all_images:\n",
        "        if img_path.parent.name == \"images\":\n",
        "            lbl_path = img_path.parent.parent / \"labels\" / (img_path.stem + \".txt\")\n",
        "        else:\n",
        "            lbl_path = img_path.with_suffix(\".txt\")\n",
        "\n",
        "        if lbl_path.exists():\n",
        "            pairs.append((img_path, lbl_path))\n",
        "\n",
        "    print(f\"Found {len(pairs)} pairs\")\n",
        "    return pairs\n",
        "\n",
        "def create_dataset_yaml(name, train_pairs, test_pairs):\n",
        "    base = WORK_DIR / name\n",
        "    dirs = {\n",
        "        'train_img': base / \"images\" / \"train\",\n",
        "        'train_lbl': base / \"labels\" / \"train\",\n",
        "        'test_img': base / \"images\" / \"test\",\n",
        "        'test_lbl': base / \"labels\" / \"test\"\n",
        "    }\n",
        "\n",
        "    for d in dirs.values():\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img, lbl in train_pairs:\n",
        "        shutil.copy2(img, dirs['train_img'] / img.name)\n",
        "        shutil.copy2(lbl, dirs['train_lbl'] / lbl.name)\n",
        "\n",
        "    for img, lbl in test_pairs:\n",
        "        shutil.copy2(img, dirs['test_img'] / img.name)\n",
        "        shutil.copy2(lbl, dirs['test_lbl'] / lbl.name)\n",
        "\n",
        "    yaml_content = {\n",
        "        'path': str(base.resolve()),\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/test',\n",
        "        'test': 'images/test',\n",
        "        'names': {0: 'ship'}\n",
        "    }\n",
        "\n",
        "    yaml_path = base / \"data.yaml\"\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
        "\n",
        "    return str(yaml_path)\n",
        "\n",
        "def main():\n",
        "    print(\"Starting Experiment: Pretrain (SMD+SeaShips+EastPylon) -> Fine-tune Sprogoe\")\n",
        "    setup_directories()\n",
        "\n",
        "    sprogoe_data = get_data_recursive(SPROGOE_DIR)\n",
        "    if not sprogoe_data:\n",
        "        print(\"Error: No data found in Sprogoe directory\")\n",
        "        return\n",
        "\n",
        "    random.seed(42)\n",
        "    random.shuffle(sprogoe_data)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for frac in FRACTIONS:\n",
        "        pct = int(frac * 100)\n",
        "        n_finetune = int(len(sprogoe_data) * frac)\n",
        "        finetune_set = sprogoe_data[:n_finetune]\n",
        "        eval_set = sprogoe_data[n_finetune:]\n",
        "\n",
        "        print(f\"Processing Fine-tune: {pct}% | Eval: {100-pct}%\")\n",
        "        exp_name = f\"EastPylon_to_Sprogoe_ft{pct}\"\n",
        "\n",
        "        try:\n",
        "            yaml_path = create_dataset_yaml(exp_name, finetune_set, eval_set)\n",
        "            model = YOLO(BASE_MODEL)\n",
        "\n",
        "            if pct == 0:\n",
        "                print(\"Running Zero-shot evaluation\")\n",
        "                res = model.val(data=yaml_path, split='test', imgsz=IMG_SIZE, batch=BATCH_SIZE, verbose=False)\n",
        "            else:\n",
        "                print(f\"Running Fine-tuning for {pct}%\")\n",
        "                model.train(\n",
        "                    data=yaml_path,\n",
        "                    epochs=EPOCHS,\n",
        "                    imgsz=IMG_SIZE,\n",
        "                    batch=BATCH_SIZE,\n",
        "                    workers=4,\n",
        "                    project=str(WORK_DIR / \"runs\"),\n",
        "                    name=exp_name,\n",
        "                    verbose=False,\n",
        "                    patience=50,\n",
        "                    save=True,\n",
        "                    exist_ok=True,\n",
        "                    **AUG_PARAMS\n",
        "                )\n",
        "                res = model.val(split='test', verbose=False)\n",
        "\n",
        "            metrics = {\n",
        "                'pretrain': 'EastPylon',\n",
        "                'target': 'Sprogoe',\n",
        "                'finetune_pct': pct,\n",
        "                'mAP50': float(res.box.map50),\n",
        "                'mAP50-95': float(res.box.map)\n",
        "            }\n",
        "            results.append(metrics)\n",
        "            print(f\"Results for {pct}%: mAP50={metrics['mAP50']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during execution: {e}\")\n",
        "\n",
        "    # Export results\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(WORK_DIR / \"results.csv\", index=False)\n",
        "\n",
        "    # Generate plots\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    axes[0].plot(df['finetune_pct'], df['mAP50'], marker='o', color='red')\n",
        "    axes[0].set_title('mAP@0.5')\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(df['finetune_pct'], df['mAP50-95'], marker='o', color='red')\n",
        "    axes[1].set_title('mAP@0.5:0.95')\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.savefig(WORK_DIR / \"results_plot.png\")\n",
        "    print(\"Experiment finished. Results saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37fc72f",
      "metadata": {
        "id": "b37fc72f",
        "outputId": "1292b95c-c7eb-4151-c3e7-25b352f13b4b"
      },
      "outputs": [],
      "source": [
        "# ================= CONFIGURATION =================\n",
        "CSV1 = \"experiment_eastpylon_to_sprogoe/results.csv\"\n",
        "CSV2 = \"experiment_sprogoe_to_eastpylon/results.csv\"\n",
        "\n",
        "LABEL1 = \"EastPylon -> Sprogoe\"\n",
        "LABEL2 = \"SMD -> Sprogoe\"\n",
        "\n",
        "# ================= DATA LOADING =================\n",
        "df1 = pd.read_csv(CSV1)\n",
        "df2 = pd.read_csv(CSV2)\n",
        "\n",
        "# ================= PLOTTING =================\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# --- Plot 1: mAP@0.5 ---\n",
        "axes[0].plot(df1['finetune_pct'], df1['mAP50'],\n",
        "             marker='o', linewidth=3, markersize=10,\n",
        "             color='#e74c3c', label=LABEL1, alpha=0.9)\n",
        "axes[0].plot(df2['finetune_pct'], df2['mAP50'],\n",
        "             marker='s', linewidth=3, markersize=10,\n",
        "             color='#3498db', label=LABEL2, alpha=0.9)\n",
        "\n",
        "axes[0].set_xlabel('Fine-tuning data (%)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('mAP@0.5', fontsize=14, fontweight='bold')\n",
        "axes[0].set_title('Transfer Learning Comparison: mAP@0.5', fontsize=16, fontweight='bold')\n",
        "axes[0].legend(fontsize=12, loc='lower right', frameon=True, shadow=True)\n",
        "axes[0].grid(True, alpha=0.3, linestyle='--')\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "# --- Plot 2: mAP@0.5:0.95 ---\n",
        "axes[1].plot(df1['finetune_pct'], df1['mAP50-95'],\n",
        "             marker='o', linewidth=3, markersize=10,\n",
        "             color='#e74c3c', label=LABEL1, alpha=0.9)\n",
        "axes[1].plot(df2['finetune_pct'], df2['mAP50-95'],\n",
        "             marker='s', linewidth=3, markersize=10,\n",
        "             color='#3498db', label=LABEL2, alpha=0.9)\n",
        "\n",
        "axes[1].set_xlabel('Fine-tuning data (%)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('mAP@0.5:0.95', fontsize=14, fontweight='bold')\n",
        "axes[1].set_title('Transfer Learning Comparison: mAP@0.5:0.95', fontsize=16, fontweight='bold')\n",
        "axes[1].legend(fontsize=12, loc='lower right', frameon=True, shadow=True)\n",
        "axes[1].grid(True, alpha=0.3, linestyle='--')\n",
        "axes[1].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparison_plot.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Comparison plot saved: comparison_plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b095f9f6",
      "metadata": {},
      "source": [
        "## Trying the code on the photos from the whole day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2195364",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load your trained YOLO model\n",
        "model = YOLO(r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\experiment_crossmix_full_metrics_eastpylon\\runs\\ft_50\\weights\\best.pt\")\n",
        "\n",
        "# 2. Define paths\n",
        "#input_folder = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb2\"\n",
        "input_folder1 = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb1\"\n",
        "#input_folder2 = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb3\"\n",
        "#output_folder = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb2_detect\"\n",
        "output_folder2 = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb1_detect\"\n",
        "#output_folder3 = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\sprogo_first_colab_frames\\14_01_2026\\frames_sb3_detect\"\n",
        "\n",
        "# 3. Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 4. Define water region; allow configurable fraction (e.g., 0.6 => bottom 60%)\n",
        "def create_water_mask(img_shape, water_percent=0.6):\n",
        "    \"\"\"Create a binary mask for the water region.\n",
        "\n",
        "    water_percent: fraction (0.0-1.0) of image height to consider as \"water\" from the bottom.\n",
        "    If water_percent==1.0 the entire image is considered.\n",
        "    \"\"\"\n",
        "    height, width = img_shape[:2]\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    # Clamp percent and compute start row\n",
        "    water_percent = max(0.0, min(1.0, float(water_percent)))\n",
        "    water_start_y = int(height * (1.0 - water_percent))\n",
        "    mask[water_start_y:, :] = 255\n",
        "\n",
        "    return mask\n",
        "\n",
        "def filter_detections_in_roi(boxes, mask):\n",
        "    \"\"\"Filter detections to only include those whose center lies in the mask.\"\"\"\n",
        "    filtered_indices = []\n",
        "\n",
        "    for idx, box in enumerate(boxes):\n",
        "        # Get bounding box coordinates\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "\n",
        "        # Calculate center point of bounding box\n",
        "        center_x = (x1 + x2) // 2\n",
        "        center_y = (y1 + y2) // 2\n",
        "\n",
        "        # Bounds check before indexing mask\n",
        "        if 0 <= center_y < mask.shape[0] and 0 <= center_x < mask.shape[1]:\n",
        "            if mask[center_y, center_x] > 0:\n",
        "                filtered_indices.append(idx)\n",
        "\n",
        "    return filtered_indices\n",
        "\n",
        "# 5. Get all image files from both input folders and process each\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
        "\n",
        "# Ensure both output folders exist\n",
        "#os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(output_folder2, exist_ok=True)\n",
        "#os.makedirs(output_folder3, exist_ok=True)\n",
        "\n",
        "# Process both input folders and save to corresponding output folders\n",
        "folders = [\n",
        "    #(input_folder, output_folder),\n",
        "    (input_folder1, output_folder2),\n",
        "    #(input_folder2, output_folder3)\n",
        "]\n",
        "\n",
        "for in_folder, out_folder in folders:\n",
        "    try:\n",
        "        image_files = [f for f in os.listdir(in_folder)\n",
        "                       if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Input folder not found: {in_folder}\")\n",
        "        continue\n",
        "\n",
        "    # Set per-folder confidence threshold and water region:\n",
        "    # - input_folder (frames_sb2): analyze whole image, conf=0.55\n",
        "    # - input_folder1 (frames_sb1): analyze bottom 60%, conf=0.60\n",
        "    if in_folder == input_folder:\n",
        "        conf_thr = 0.65\n",
        "        water_percent = 0.6\n",
        "    else:\n",
        "        conf_thr = 0.60\n",
        "        water_percent = 0.60\n",
        "\n",
        "    print(f\"Found {len(image_files)} images in {in_folder} to process -> {out_folder} (conf={conf_thr}, water_percent={water_percent})\")\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(in_folder, img_file)\n",
        "\n",
        "        # Load image to get dimensions and create mask\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Could not read: {img_file} in {in_folder}\")\n",
        "            continue\n",
        "\n",
        "        # Create water mask according to folder-specific percentage\n",
        "        water_mask = create_water_mask(img.shape, water_percent=water_percent)\n",
        "\n",
        "        # Run prediction on full image with per-folder confidence\n",
        "        results = model.predict(\n",
        "            source=img_path,\n",
        "            save=False,\n",
        "            show=False,\n",
        "            conf=conf_thr,\n",
        "            iou=0.0\n",
        "        )\n",
        "\n",
        "        # Filter detections to only water region\n",
        "        if len(results[0].boxes) > 0:\n",
        "            valid_indices = filter_detections_in_roi(results[0].boxes, water_mask)\n",
        "\n",
        "            if valid_indices:\n",
        "                # Keep only detections in water region\n",
        "                results[0].boxes = results[0].boxes[valid_indices]\n",
        "\n",
        "                # Save the image with filtered detections\n",
        "                output_path = os.path.join(out_folder, img_file)\n",
        "                results[0].save(filename=output_path)\n",
        "                print(f\"Saved: {img_file} ({len(valid_indices)} detections in water) -> {out_folder}\")\n",
        "            else:\n",
        "                print(f\"Skipped: {img_file} (no detections in water region) in {in_folder}\")\n",
        "        else:\n",
        "            pass  # No detections at all\n",
        "\n",
        "print(\"\\nProcessing complete! Detected images saved to:\")\n",
        "print(f\" - {output_folder}\")\n",
        "print(f\" - {output_folder2}\")\n",
        "#print(f\" - {output_folder3}\")\n",
        "print(\"Analyzing bottom 60% of each image (water region)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a6ee84",
      "metadata": {},
      "source": [
        "### Ground truth and detection (for the report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea9bcf1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PATH CONFIGURATION ---\n",
        "# Provide paths to your files:\n",
        "IMAGE_PATH = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\camera_2\\train\\images\\frame_20251214_150720_jpg.rf.cacb49ad7037e8f913d1b7fb17b367fa.jpg\"  # Your image\n",
        "LABEL_PATH = r\"C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\camera_2\\train\\labels\\frame_20251214_150720_jpg.rf.cacb49ad7037e8f913d1b7fb17b367fa.txt\"   # Ground Truth txt file (YOLO format)\n",
        "MODEL_PATH = r'C:\\Users\\szymo\\Desktop\\DTU\\3rd_semester\\Individual_project_demo\\runs\\detect\\train4\\weights\\best.pt'                               # Path to your trained .pt model\n",
        "OUTPUT_PATH = '2nd_camera_detect_simple.jpg'         # Output file destination\n",
        "\n",
        "def draw_yolo_box(img, line, color, label_text):\n",
        "    \"\"\"\n",
        "    Draws a bounding box from normalized YOLO format onto the image.\n",
        "    YOLO format in txt: class x_center y_center width height\n",
        "    \"\"\"\n",
        "    h, w, _ = img.shape\n",
        "    parts = line.strip().split()\n",
        "\n",
        "    # Data parsing (assuming class_id is the first element, followed by coordinates)\n",
        "    # class_id = int(parts[0])\n",
        "    x_center, y_center, box_w, box_h = map(float, parts[1:5])\n",
        "\n",
        "    # Convert from relative (0-1) to pixel coordinates\n",
        "    x_c, y_c = x_center * w, y_center * h\n",
        "    b_w, b_h = box_w * w, box_h * h\n",
        "\n",
        "    # Calculate top-left corner (x_min, y_min) and bottom-right corner\n",
        "    x_min = int(x_c - (b_w / 2))\n",
        "    y_min = int(y_c - (b_h / 2))\n",
        "    x_max = int(x_c + (b_w / 2))\n",
        "    y_max = int(y_c + (b_h / 2))\n",
        "\n",
        "    # Draw the rectangle\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 3)\n",
        "\n",
        "    # Add label text\n",
        "    cv2.putText(img, label_text, (x_min, y_min - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "# --- 1. IMAGE LOADING ---\n",
        "image = cv2.imread(IMAGE_PATH)\n",
        "if image is None:\n",
        "    print(f\"Error: Image not found at {IMAGE_PATH}\")\n",
        "    exit()\n",
        "\n",
        "image_vis = image.copy() # Copy for visualization/drawing\n",
        "\n",
        "# --- 2. DRAW GROUND TRUTH (GREEN) ---\n",
        "# Reading the txt file (typically exported from Roboflow)\n",
        "if os.path.exists(LABEL_PATH):\n",
        "    with open(LABEL_PATH, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            # Drawing the GT box (BGR color (0, 255, 0) is Green)\n",
        "            draw_yolo_box(image_vis, line, (0, 255, 0), \"Ground Truth\")\n",
        "else:\n",
        "    print(\"Warning: Ground Truth file (.txt) not found\")\n",
        "\n",
        "# --- 3. DRAW MODEL PREDICTIONS (RED) ---\n",
        "print(\"Running model inference...\")\n",
        "model = YOLO(MODEL_PATH)\n",
        "results = model.predict(IMAGE_PATH, conf=0.25) # conf - confidence threshold\n",
        "\n",
        "for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "        # Get xyxy coordinates (x_min, y_min, x_max, y_max)\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "        conf = box.conf[0].item()\n",
        "\n",
        "        # Draw Prediction box (BGR color (0, 0, 255) is Red)\n",
        "        cv2.rectangle(image_vis, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
        "\n",
        "        label = f\"Pred: {conf:.2f}\"\n",
        "        # Position label below the box to avoid overlapping with GT labels\n",
        "        cv2.putText(image_vis, label, (x1, y2 + 25),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "# --- 4. DISPLAY AND SAVE ---\n",
        "# Convert BGR (OpenCV default) to RGB (Matplotlib default) for correct color rendering\n",
        "image_rgb = cv2.cvtColor(image_vis, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.title(\"Green: Ground Truth | Red: Model Prediction\")\n",
        "plt.show()\n",
        "\n",
        "# Save output to disk\n",
        "cv2.imwrite(OUTPUT_PATH, image_vis)\n",
        "print(f\"Resulting image saved as: {OUTPUT_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CUDA_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
